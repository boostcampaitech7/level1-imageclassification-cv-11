{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af8a2c0-45fe-4d13-bebd-0dca87a7b71f",
   "metadata": {
    "papermill": {
     "duration": 0.003689,
     "end_time": "2024-09-23T08:45:12.717721",
     "exception": false,
     "start_time": "2024-09-23T08:45:12.714032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c611c8-2226-433c-bf5f-343cc0b094af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:12.730333Z",
     "iopub.status.busy": "2024-09-23T08:45:12.730152Z",
     "iopub.status.idle": "2024-09-23T08:45:14.954817Z",
     "shell.execute_reply": "2024-09-23T08:45:14.954330Z"
    },
    "papermill": {
     "duration": 2.229568,
     "end_time": "2024-09-23T08:45:14.955924",
     "exception": false,
     "start_time": "2024-09-23T08:45:12.726356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 필요 library들을 import합니다.\n",
    "import os\n",
    "from typing import Tuple, Any, Callable, List, Optional, Union\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from torchcam.methods import GradCAM\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from radam import Radam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d0864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:14.963027Z",
     "iopub.status.busy": "2024-09-23T08:45:14.962816Z",
     "iopub.status.idle": "2024-09-23T08:45:14.968849Z",
     "shell.execute_reply": "2024-09-23T08:45:14.968509Z"
    },
    "papermill": {
     "duration": 0.010458,
     "end_time": "2024-09-23T08:45:14.969626",
     "exception": false,
     "start_time": "2024-09-23T08:45:14.959168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e9123b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:14.976302Z",
     "iopub.status.busy": "2024-09-23T08:45:14.976203Z",
     "iopub.status.idle": "2024-09-23T08:45:14.979093Z",
     "shell.execute_reply": "2024-09-23T08:45:14.978884Z"
    },
    "papermill": {
     "duration": 0.007103,
     "end_time": "2024-09-23T08:45:14.979788",
     "exception": false,
     "start_time": "2024-09-23T08:45:14.972685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d69e6a-a719-4a97-92ca-6354c873313f",
   "metadata": {
    "papermill": {
     "duration": 0.003114,
     "end_time": "2024-09-23T08:45:14.986159",
     "exception": false,
     "start_time": "2024-09-23T08:45:14.983045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f97229-e29f-479d-abab-0db8219d1803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:14.993342Z",
     "iopub.status.busy": "2024-09-23T08:45:14.993200Z",
     "iopub.status.idle": "2024-09-23T08:45:14.997411Z",
     "shell.execute_reply": "2024-09-23T08:45:14.997110Z"
    },
    "papermill": {
     "duration": 0.008743,
     "end_time": "2024-09-23T08:45:14.998138",
     "exception": false,
     "start_time": "2024-09-23T08:45:14.989395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        root_dir: str, \n",
    "        info_df: pd.DataFrame, \n",
    "        transform: Callable,\n",
    "        is_inference: bool = False\n",
    "    ):\n",
    "        # 데이터셋의 기본 경로, 이미지 변환 방법, 이미지 경로 및 레이블을 초기화합니다.\n",
    "        self.root_dir = root_dir  # 이미지 파일들이 저장된 기본 디렉토리\n",
    "        self.transform = transform  # 이미지에 적용될 변환 처리\n",
    "        self.is_inference = is_inference # 추론인지 확인\n",
    "        self.image_paths = info_df['image_path'].tolist()  # 이미지 파일 경로 목록\n",
    "        \n",
    "        if not self.is_inference:\n",
    "            self.targets = info_df['target'].tolist()  # 각 이미지에 대한 레이블 목록\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # 데이터셋의 총 이미지 수를 반환합니다.\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[Tuple[torch.Tensor, int], torch.Tensor]:\n",
    "        # 주어진 인덱스에 해당하는 이미지를 로드하고 변환을 적용한 후, 이미지와 레이블을 반환합니다.\n",
    "        img_path = os.path.join(self.root_dir, self.image_paths[index])  # 이미지 경로 조합\n",
    "        # image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # 그레이스케일로 읽기\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # 3채널 RGB로 변환     \n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)  # 이미지를 BGR 컬러 포맷의 numpy array로 읽어옵니다.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR 포맷을 RGB 포맷으로 변환합니다.\n",
    "        image = self.transform(image)  # 설정된 이미지 변환을 적용합니다.\n",
    "\n",
    "        if self.is_inference:\n",
    "            return image\n",
    "        else:\n",
    "            target = self.targets[index]  # 해당 이미지의 레이블\n",
    "            return image, target  # 변환된 이미지와 레이블을 튜플 형태로 반환합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07d2d0-9585-45ce-8ece-4f69b98f6dd4",
   "metadata": {
    "papermill": {
     "duration": 0.003027,
     "end_time": "2024-09-23T08:45:15.004199",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.001172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transform Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1855c1-cf13-476d-aabd-d78e9e082ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.011264Z",
     "iopub.status.busy": "2024-09-23T08:45:15.011071Z",
     "iopub.status.idle": "2024-09-23T08:45:15.015263Z",
     "shell.execute_reply": "2024-09-23T08:45:15.015041Z"
    },
    "papermill": {
     "duration": 0.008674,
     "end_time": "2024-09-23T08:45:15.015958",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.007284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorchvisionTransform:\n",
    "    def __init__(self, is_train: bool = True):\n",
    "        # 공통 변환 설정: 이미지 리사이즈, 텐서 변환, 정규화\n",
    "        common_transforms = [\n",
    "            transforms.Resize((224, 224)),  # 이미지를 224x224 크기로 리사이즈\n",
    "            transforms.ToTensor(),  # 이미지를 PyTorch 텐서로 변환\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n",
    "        ]\n",
    "        \n",
    "        if is_train:\n",
    "            # 훈련용 변환: 랜덤 수평 뒤집기, 랜덤 회전, 색상 조정 추가\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.RandomHorizontalFlip(p=0.5),  # 50% 확률로 이미지를 수평 뒤집기\n",
    "                    transforms.RandomRotation(15),  # 최대 15도 회전\n",
    "                    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # 밝기 및 대비 조정\n",
    "                ] + common_transforms\n",
    "            )\n",
    "        else:\n",
    "            # 검증/테스트용 변환: 공통 변환만 적용\n",
    "            self.transform = transforms.Compose(common_transforms)\n",
    "\n",
    "    def __call__(self, image: np.ndarray) -> torch.Tensor:\n",
    "        image = Image.fromarray(image)  # numpy 배열을 PIL 이미지로 변환\n",
    "        \n",
    "        transformed = self.transform(image)  # 설정된 변환을 적용\n",
    "        \n",
    "        return transformed  # 변환된 이미지 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsharpMask(A.ImageOnlyTransform):\n",
    "    def __init__(self, kernel_size=7, sigma=1.5, amount=1.5, threshold=0, always_apply=False, p=1.0):\n",
    "        super(UnsharpMask, self).__init__(always_apply, p)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.amount = amount\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        return self.unsharp_mask(image)\n",
    "\n",
    "    def unsharp_mask(self, image):\n",
    "        blurred = cv2.GaussianBlur(image, (self.kernel_size, self.kernel_size), self.sigma)\n",
    "        sharpened = cv2.addWeighted(image, 1.0 + self.amount, blurred, -self.amount, 0)\n",
    "        if self.threshold > 0:\n",
    "            low_contrast_mask = np.absolute(image - blurred) < self.threshold\n",
    "            np.copyto(sharpened, image, where=low_contrast_mask)\n",
    "        return sharpened\n",
    "\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, is_train: bool = True):\n",
    "        # 공통 변환 설정: 이미지 리사이즈, 그레이스케일 변환, 언샤프 마스크, 정규화, 텐서 변환\n",
    "        common_transforms = [\n",
    "            A.Resize(224, 224),  # 이미지를 224x224 크기로 리사이즈\n",
    "            A.ToGray(p=1.0),  # 그레이스케일 변환\n",
    "            UnsharpMask(kernel_size=7, sigma=1.5, amount=1.5, threshold=0, p=1.0),  # 언샤프 마스크 적용\n",
    "            A.Normalize(mean=[0.5], std=[0.5]),  # 그레이스케일 이미지에 맞는 정규화\n",
    "            ToTensorV2(),  # albumentations에서 제공하는 PyTorch 텐서 변환\n",
    "        ]\n",
    "\n",
    "        if is_train:\n",
    "            # 훈련용 변환: 랜덤 크롭, 랜덤 수평 뒤집기, 랜덤 회전 추가\n",
    "            self.transform = A.Compose(\n",
    "                [\n",
    "                    A.HorizontalFlip(p=0.9),  # 90% 확률로 이미지를 수평 뒤집기\n",
    "                    A.Rotate(limit=30),  # 최대 30도 회전\n",
    "                    A.RandomBrightnessContrast(brightness_limit=(-0.2, -0.2), contrast_limit=0, p=0.9), # 20% 어둡게\n",
    "                    A.GaussianBlur(blur_limit=(3, 5), p=0.6), # 약간의 블러 추가\n",
    "                    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.5), # 50% 확률로 블럭 추가\n",
    "                    A.GridDistortion(always_apply=False, p=1, num_steps=1, distort_limit=(-0.03, 0.05), interpolation=2, border_mode=0, value=(0, 0, 0), mask_value=None)\n",
    "                ] + common_transforms\n",
    "            )\n",
    "        else:\n",
    "            # 검증/테스트용 변환: 공통 변환만 적용\n",
    "            self.transform = A.Compose(common_transforms)\n",
    "\n",
    "    def __call__(self, image) -> torch.Tensor:\n",
    "        # 이미지가 NumPy 배열인지 확인\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            raise TypeError(\"Image should be a NumPy array (OpenCV format).\")\n",
    "\n",
    "        # 이미지에 변환 적용 및 결과 반환\n",
    "        transformed = self.transform(image=image)  # 이미지에 설정된 변환을 적용\n",
    "\n",
    "        return transformed['image']  # 변환된 이미지의 텐서를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82f3416-86f2-430f-9260-d23904e757e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.036233Z",
     "iopub.status.busy": "2024-09-23T08:45:15.036086Z",
     "iopub.status.idle": "2024-09-23T08:45:15.038561Z",
     "shell.execute_reply": "2024-09-23T08:45:15.038347Z"
    },
    "papermill": {
     "duration": 0.006885,
     "end_time": "2024-09-23T08:45:15.039291",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.032406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformSelector:\n",
    "    \"\"\"\n",
    "    이미지 변환 라이브러리를 선택하기 위한 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, transform_type: str):\n",
    "\n",
    "        # 지원하는 변환 라이브러리인지 확인\n",
    "        if transform_type in [\"torchvision\", \"albumentations\"]:\n",
    "            self.transform_type = transform_type\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown transformation library specified.\")\n",
    "\n",
    "    def get_transform(self, is_train: bool):\n",
    "        \n",
    "        # 선택된 라이브러리에 따라 적절한 변환 객체를 생성\n",
    "        if self.transform_type == 'torchvision':\n",
    "            transform = TorchvisionTransform(is_train=is_train)\n",
    "        \n",
    "        elif self.transform_type == 'albumentations':\n",
    "            transform = AlbumentationsTransform(is_train=is_train)\n",
    "        \n",
    "        return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938bcb2-9257-49cb-8d05-dd4a7bb25665",
   "metadata": {
    "papermill": {
     "duration": 0.003035,
     "end_time": "2024-09-23T08:45:15.045328",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.042293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f16fb24a-8d34-4ed6-8a33-2d153d12d190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.051875Z",
     "iopub.status.busy": "2024-09-23T08:45:15.051736Z",
     "iopub.status.idle": "2024-09-23T08:45:15.054730Z",
     "shell.execute_reply": "2024-09-23T08:45:15.054520Z"
    },
    "papermill": {
     "duration": 0.007183,
     "end_time": "2024-09-23T08:45:15.055452",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.048269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    간단한 CNN 아키텍처를 정의하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # 순전파 함수 정의\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91493ca-c5c2-4950-916a-cc4304c7ad4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.062110Z",
     "iopub.status.busy": "2024-09-23T08:45:15.061965Z",
     "iopub.status.idle": "2024-09-23T08:45:15.064697Z",
     "shell.execute_reply": "2024-09-23T08:45:15.064477Z"
    },
    "papermill": {
     "duration": 0.00713,
     "end_time": "2024-09-23T08:45:15.065561",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.058431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorchvisionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Torchvision에서 제공하는 사전 훈련된 모델을 사용하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str, \n",
    "        num_classes: int, \n",
    "        pretrained: bool\n",
    "    ):\n",
    "        super(TorchvisionModel, self).__init__()\n",
    "        self.model = models.__dict__[model_name](pretrained=pretrained)\n",
    "        \n",
    "        # 모델의 최종 분류기 부분을 사용자 정의 클래스 수에 맞게 조정\n",
    "        if 'fc' in dir(self.model):\n",
    "            num_ftrs = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        elif 'classifier' in dir(self.model):\n",
    "            num_ftrs = self.model.classifier[-1].in_features\n",
    "            self.model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f28c8e4f-a914-4b12-982e-d4a58863c717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.072685Z",
     "iopub.status.busy": "2024-09-23T08:45:15.072531Z",
     "iopub.status.idle": "2024-09-23T08:45:15.075057Z",
     "shell.execute_reply": "2024-09-23T08:45:15.074642Z"
    },
    "papermill": {
     "duration": 0.007109,
     "end_time": "2024-09-23T08:45:15.075859",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.068750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Timm 라이브러리를 사용하여 다양한 사전 훈련된 모델을 제공하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str, \n",
    "        num_classes: int, \n",
    "        pretrained: bool\n",
    "    ):\n",
    "        super(TimmModel, self).__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2da081-9010-431d-a049-835d7bbea4a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.082475Z",
     "iopub.status.busy": "2024-09-23T08:45:15.082343Z",
     "iopub.status.idle": "2024-09-23T08:45:15.085154Z",
     "shell.execute_reply": "2024-09-23T08:45:15.084751Z"
    },
    "papermill": {
     "duration": 0.007213,
     "end_time": "2024-09-23T08:45:15.086070",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.078857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelSelector:\n",
    "    \"\"\"\n",
    "    사용할 모델 유형을 선택하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_type: str, \n",
    "        num_classes: int, \n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        # 모델 유형에 따라 적절한 모델 객체를 생성\n",
    "        if model_type == 'simple':\n",
    "            self.model = SimpleCNN(num_classes=num_classes)\n",
    "        \n",
    "        elif model_type == 'torchvision':\n",
    "            self.model = TorchvisionModel(num_classes=num_classes, **kwargs)\n",
    "        \n",
    "        elif model_type == 'timm':\n",
    "            self.model = TimmModel(num_classes=num_classes, **kwargs)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown model type specified.\")\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "\n",
    "        # 생성된 모델 객체 반환\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2977c7b-bc39-48f7-8155-ef6b6a03d6f8",
   "metadata": {
    "papermill": {
     "duration": 0.003157,
     "end_time": "2024-09-23T08:45:15.092205",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.089048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8294bb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.099566Z",
     "iopub.status.busy": "2024-09-23T08:45:15.099394Z",
     "iopub.status.idle": "2024-09-23T08:45:15.104824Z",
     "shell.execute_reply": "2024-09-23T08:45:15.104397Z"
    },
    "papermill": {
     "duration": 0.010292,
     "end_time": "2024-09-23T08:45:15.105501",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.095209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmUpRestarts(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1a6ebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.112526Z",
     "iopub.status.busy": "2024-09-23T08:45:15.112372Z",
     "iopub.status.idle": "2024-09-23T08:45:15.121051Z",
     "shell.execute_reply": "2024-09-23T08:45:15.120511Z"
    },
    "papermill": {
     "duration": 0.013196,
     "end_time": "2024-09-23T08:45:15.121779",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.108583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \"\"\"Sets the learning rate of each parameter group according to\n",
    "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
    "    rate between two boundaries with a constant frequency, as detailed in\n",
    "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
    "    The distance between the two boundaries can be scaled on a per-iteration\n",
    "    or per-cycle basis.\n",
    "\n",
    "    Cyclical learning rate policy changes the learning rate after every batch.\n",
    "    `step` should be called after a batch has been used for training.\n",
    "\n",
    "    This class has three built-in policies, as put forth in the paper:\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
    "        cycle iteration.\n",
    "\n",
    "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
    "\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        base_lr (float or list): Initial learning rate which is the\n",
    "            lower boundary in the cycle for each parameter group.\n",
    "        max_lr (float or list): Upper learning rate boundaries in the cycle\n",
    "            for each parameter group. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore\n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size_up (int): Number of training iterations in the\n",
    "            increasing half of a cycle. Default: 2000\n",
    "        step_size_down (int): Number of training iterations in the\n",
    "            decreasing half of a cycle. If step_size_down is None,\n",
    "            it is set to step_size_up. Default: None\n",
    "        mode (str): One of {triangular, triangular2, exp_range}.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "            Default: 'triangular'\n",
    "        gamma (float): Constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "            Default: 1.0\n",
    "        scale_fn (function): Custom scaling policy defined by a single\n",
    "            argument lambda function, where\n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            If specified, then 'mode' is ignored.\n",
    "            Default: None\n",
    "        scale_mode (str): {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on\n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle).\n",
    "            Default: 'cycle'\n",
    "        cycle_momentum (bool): If ``True``, momentum is cycled inversely\n",
    "            to learning rate between 'base_momentum' and 'max_momentum'.\n",
    "            Default: True\n",
    "        base_momentum (float or list): Initial momentum which is the\n",
    "            lower boundary in the cycle for each parameter group.\n",
    "            Default: 0.8\n",
    "        max_momentum (float or list): Upper momentum boundaries in the cycle\n",
    "            for each parameter group. Functionally,\n",
    "            it defines the cycle amplitude (max_momentum - base_momentum).\n",
    "            The momentum at any cycle is the difference of max_momentum\n",
    "            and some scaling of the amplitude; therefore\n",
    "            base_momentum may not actually be reached depending on\n",
    "            scaling function. Default: 0.9\n",
    "        last_epoch (int): The index of the last batch. This parameter is used when\n",
    "            resuming a training job. Since `step()` should be invoked after each\n",
    "            batch instead of after each epoch, this number represents the total\n",
    "            number of *batches* computed, not the total number of epochs computed.\n",
    "            When last_epoch=-1, the schedule is started from the beginning.\n",
    "            Default: -1\n",
    "\n",
    "    Example:\n",
    "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "        >>> scheduler = torch.optim.CyclicLR(optimizer)\n",
    "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
    "        >>> for epoch in range(10):\n",
    "        >>>     for batch in data_loader:\n",
    "        >>>         train_batch(...)\n",
    "        >>>         scheduler.step()\n",
    "\n",
    "\n",
    "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
    "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 optimizer,\n",
    "                 base_lr,\n",
    "                 max_lr,\n",
    "                 step_size_up=2000,\n",
    "                 step_size_down=None,\n",
    "                 mode='triangular',\n",
    "                 gamma=1.,\n",
    "                 scale_fn=None,\n",
    "                 scale_mode='cycle',\n",
    "                 cycle_momentum=True,\n",
    "                 base_momentum=0.8,\n",
    "                 max_momentum=0.9,\n",
    "                 last_epoch=-1):\n",
    "\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        base_lrs = self._format_param('base_lr', optimizer, base_lr)\n",
    "        if last_epoch == -1:\n",
    "            for lr, group in zip(base_lrs, optimizer.param_groups):\n",
    "                group['lr'] = lr\n",
    "\n",
    "        self.max_lrs = self._format_param('max_lr', optimizer, max_lr)\n",
    "\n",
    "        step_size_up = float(step_size_up)\n",
    "        step_size_down = float(step_size_down) if step_size_down is not None else step_size_up\n",
    "        self.total_size = step_size_up + step_size_down\n",
    "        self.step_ratio = step_size_up / self.total_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.cycle_momentum = cycle_momentum\n",
    "        if cycle_momentum:\n",
    "            if 'momentum' not in optimizer.defaults:\n",
    "                raise ValueError('optimizer must support momentum with `cycle_momentum` option enabled')\n",
    "\n",
    "            base_momentums = self._format_param('base_momentum', optimizer, base_momentum)\n",
    "            if last_epoch == -1:\n",
    "                for momentum, group in zip(base_momentums, optimizer.param_groups):\n",
    "                    group['momentum'] = momentum\n",
    "        self.base_momentums = list(map(lambda group: group['momentum'], optimizer.param_groups))\n",
    "        self.max_momentums = self._format_param('max_momentum', optimizer, max_momentum)\n",
    "\n",
    "        super(CyclicLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def _format_param(self, name, optimizer, param):\n",
    "        \"\"\"Return correctly formatted lr/momentum for each param group.\"\"\"\n",
    "        if isinstance(param, (list, tuple)):\n",
    "            if len(param) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} values for {}, got {}\".format(\n",
    "                    len(optimizer.param_groups), name, len(param)))\n",
    "            return param\n",
    "        else:\n",
    "            return [param] * len(optimizer.param_groups)\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"Calculates the learning rate at batch index. This function treats\n",
    "        `self.last_epoch` as the last batch index.\n",
    "\n",
    "        If `self.cycle_momentum` is ``True``, this function has a side effect of\n",
    "        updating the optimizer's momentum.\n",
    "        \"\"\"\n",
    "        cycle = math.floor(1 + self.last_epoch / self.total_size)\n",
    "        x = 1. + self.last_epoch / self.total_size - cycle\n",
    "        if x <= self.step_ratio:\n",
    "            scale_factor = x / self.step_ratio\n",
    "        else:\n",
    "            scale_factor = (x - 1) / (self.step_ratio - 1)\n",
    "\n",
    "        lrs = []\n",
    "        for base_lr, max_lr in zip(self.base_lrs, self.max_lrs):\n",
    "            base_height = (max_lr - base_lr) * scale_factor\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_epoch)\n",
    "            lrs.append(lr)\n",
    "\n",
    "        if self.cycle_momentum:\n",
    "            momentums = []\n",
    "            for base_momentum, max_momentum in zip(self.base_momentums, self.max_momentums):\n",
    "                base_height = (max_momentum - base_momentum) * scale_factor\n",
    "                if self.scale_mode == 'cycle':\n",
    "                    momentum = max_momentum - base_height * self.scale_fn(cycle)\n",
    "                else:\n",
    "                    momentum = max_momentum - base_height * self.scale_fn(self.last_epoch)\n",
    "                momentums.append(momentum)\n",
    "            for param_group, momentum in zip(self.optimizer.param_groups, momentums):\n",
    "                param_group['momentum'] = momentum\n",
    "\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1b52141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.128839Z",
     "iopub.status.busy": "2024-09-23T08:45:15.128462Z",
     "iopub.status.idle": "2024-09-23T08:45:15.131676Z",
     "shell.execute_reply": "2024-09-23T08:45:15.131370Z"
    },
    "papermill": {
     "duration": 0.007394,
     "end_time": "2024-09-23T08:45:15.132263",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.124869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes: int, smoothing: float = 0.1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "\n",
    "    def forward(self, x: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        log_probs = F.log_softmax(x, dim=-1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(log_probs)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c51e6c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.138791Z",
     "iopub.status.busy": "2024-09-23T08:45:15.138660Z",
     "iopub.status.idle": "2024-09-23T08:45:15.141338Z",
     "shell.execute_reply": "2024-09-23T08:45:15.141055Z"
    },
    "papermill": {
     "duration": 0.006714,
     "end_time": "2024-09-23T08:45:15.141981",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.135267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Cross Entropy Loss 계산\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        # 예측 확률 계산\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        # Focal Loss 계산\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97471eb3-a979-4fb3-b976-6c3177c79f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.148557Z",
     "iopub.status.busy": "2024-09-23T08:45:15.148414Z",
     "iopub.status.idle": "2024-09-23T08:45:15.151258Z",
     "shell.execute_reply": "2024-09-23T08:45:15.150571Z"
    },
    "papermill": {
     "duration": 0.007315,
     "end_time": "2024-09-23T08:45:15.152242",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.144927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    모델의 손실함수를 계산하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        outputs: torch.Tensor, \n",
    "        targets: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "    \n",
    "        return self.loss_fn(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e3d21-5ab8-41b0-aa5c-e62ace8dc6a6",
   "metadata": {
    "papermill": {
     "duration": 0.003061,
     "end_time": "2024-09-23T08:45:15.159091",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.156030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a90c673-6672-4066-a9ec-9975d7842be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.166158Z",
     "iopub.status.busy": "2024-09-23T08:45:15.165972Z",
     "iopub.status.idle": "2024-09-23T08:45:15.174090Z",
     "shell.execute_reply": "2024-09-23T08:45:15.173530Z"
    },
    "papermill": {
     "duration": 0.012489,
     "end_time": "2024-09-23T08:45:15.174721",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.162232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        device: torch.device, \n",
    "        train_loader: DataLoader, \n",
    "        val_loader: DataLoader, \n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler: optim.lr_scheduler,\n",
    "        loss_fn: torch.nn.modules.loss._Loss, \n",
    "        epochs: int,\n",
    "        result_path: str\n",
    "    ):\n",
    "        # 클래스 초기화: 모델, 디바이스, 데이터 로더 등 설정\n",
    "        self.model = model  # 훈련할 모델\n",
    "        self.device = device  # 연산을 수행할 디바이스 (CPU or GPU)\n",
    "        self.train_loader = train_loader  # 훈련 데이터 로더\n",
    "        self.val_loader = val_loader  # 검증 데이터 로더\n",
    "        self.optimizer = optimizer  # 최적화 알고리즘\n",
    "        self.scheduler = scheduler  # 학습률 스케줄러\n",
    "        self.loss_fn = loss_fn  # 손실 함수\n",
    "        self.epochs = epochs  # 총 훈련 에폭 수\n",
    "        self.result_path = result_path  # 모델 저장 경로\n",
    "        self.best_models = []  # 가장 좋은 상위 3개 모델의 정보를 저장할 리스트\n",
    "        self.lowest_loss = float('inf')  # 가장 낮은 Loss를 저장할 변수\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        # 모델 저장 경로 설정\n",
    "        os.makedirs(self.result_path, exist_ok=True)\n",
    "\n",
    "        # 현재 에폭 모델 저장\n",
    "        current_model_path = os.path.join(self.result_path, f'model_epoch_{epoch}_loss_{loss:.4f}.pt')\n",
    "        torch.save(self.model.state_dict(), current_model_path)\n",
    "\n",
    "        # 최상위 3개 모델 관리\n",
    "        self.best_models.append((loss, epoch, current_model_path))\n",
    "        self.best_models.sort()\n",
    "        if len(self.best_models) > 3:\n",
    "            _, _, path_to_remove = self.best_models.pop(-1)  # 가장 높은 손실 모델 삭제\n",
    "            if os.path.exists(path_to_remove):\n",
    "                os.remove(path_to_remove)\n",
    "\n",
    "        # 가장 낮은 손실의 모델 저장\n",
    "        if loss < self.lowest_loss:\n",
    "            self.lowest_loss = loss\n",
    "            best_model_path = os.path.join(self.result_path, 'best_model.pt')\n",
    "            torch.save(self.model.state_dict(), best_model_path)\n",
    "            print(f\"Save {epoch}epoch result. Loss = {loss:.4f}\")\n",
    "\n",
    "    def train_epoch(self) -> float:\n",
    "        # 한 에폭 동안의 훈련을 진행\n",
    "        self.model.train()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "                \n",
    "        progress_bar = tqdm(self.train_loader, desc=\"Training\", leave=False)\n",
    "\n",
    "        for images, targets in progress_bar:\n",
    "            images, targets = images.to(self.device), targets.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)  # 예측된 클래스\n",
    "            correct_predictions += (preds == targets).sum().item()  # 맞춘 예측 개수\n",
    "            total_samples += targets.size(0)  # 전체 샘플 수\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "            \n",
    "        accuracy = correct_predictions / total_samples * 100  # 정확도 계산\n",
    "        print(f\"Train Accuracy: {accuracy:.2f}%\")            \n",
    "\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    def validate(self) -> float:\n",
    "        # 모델의 검증을 진행\n",
    "        self.model.eval()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        progress_bar = tqdm(self.val_loader, desc=\"Validating\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in progress_bar:\n",
    "                images, targets = images.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # 정확도 계산\n",
    "                _, preds = torch.max(outputs, 1)  # 예측된 클래스\n",
    "                correct_predictions += (preds == targets).sum().item()  # 맞춘 예측 개수\n",
    "                total_samples += targets.size(0)  # 전체 샘플 수                \n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        accuracy = correct_predictions / total_samples * 100  # 정확도 계산\n",
    "        print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        return total_loss / len(self.val_loader)\n",
    "\n",
    "    def train(self) -> float:\n",
    "        # 전체 훈련 과정을 관리\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "\n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss = self.validate()\n",
    "\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Learning Rate: {current_lr:.6f}\\n\")\n",
    "\n",
    "            self.save_model(epoch, val_loss)\n",
    "            self.scheduler.step()\n",
    "\n",
    "        # 학습 완료 후 최종 검증 손실 반환\n",
    "        return self.lowest_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f41c09-318a-4f2e-bdca-68d8a07e9938",
   "metadata": {
    "papermill": {
     "duration": 0.003328,
     "end_time": "2024-09-23T08:45:15.181269",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.177941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "698783c4-ac2a-4e66-82aa-637df06ce012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.188509Z",
     "iopub.status.busy": "2024-09-23T08:45:15.188284Z",
     "iopub.status.idle": "2024-09-23T08:45:15.190774Z",
     "shell.execute_reply": "2024-09-23T08:45:15.190474Z"
    },
    "papermill": {
     "duration": 0.007007,
     "end_time": "2024-09-23T08:45:15.191369",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.184362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습에 사용할 장비를 선택.\n",
    "# torch라이브러리에서 gpu를 인식할 경우, cuda로 설정.\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76cfe17e-fb14-42e4-84ae-b6773f0b78fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.197874Z",
     "iopub.status.busy": "2024-09-23T08:45:15.197780Z",
     "iopub.status.idle": "2024-09-23T08:45:15.199562Z",
     "shell.execute_reply": "2024-09-23T08:45:15.199289Z"
    },
    "papermill": {
     "duration": 0.005722,
     "end_time": "2024-09-23T08:45:15.200103",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.194381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "traindata_dir = \"../data/train\"\n",
    "traindata_info_file = \"../data/train.csv\"\n",
    "save_result_path = \"../train_result_code8_ca_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa914f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.206633Z",
     "iopub.status.busy": "2024-09-23T08:45:15.206497Z",
     "iopub.status.idle": "2024-09-23T08:45:15.215944Z",
     "shell.execute_reply": "2024-09-23T08:45:15.215600Z"
    },
    "papermill": {
     "duration": 0.01377,
     "end_time": "2024-09-23T08:45:15.216837",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.203067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "train_info = pd.read_csv(traindata_info_file)\n",
    "\n",
    "# 총 class의 수를 측정.\n",
    "num_classes = len(train_info['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db231faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.223959Z",
     "iopub.status.busy": "2024-09-23T08:45:15.223783Z",
     "iopub.status.idle": "2024-09-23T08:45:15.225949Z",
     "shell.execute_reply": "2024-09-23T08:45:15.225557Z"
    },
    "papermill": {
     "duration": 0.006595,
     "end_time": "2024-09-23T08:45:15.226703",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.220108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KFold 설정\n",
    "n_splits = 5  # 5-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfcf3912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.233851Z",
     "iopub.status.busy": "2024-09-23T08:45:15.233538Z",
     "iopub.status.idle": "2024-09-23T08:45:15.237152Z",
     "shell.execute_reply": "2024-09-23T08:45:15.236850Z"
    },
    "papermill": {
     "duration": 0.008464,
     "end_time": "2024-09-23T08:45:15.238302",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.229838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습에 사용할 Transform을 선언.\n",
    "transform_selector = TransformSelector(\n",
    "    transform_type = \"albumentations\"\n",
    ")\n",
    "train_transform = transform_selector.get_transform(is_train=True)\n",
    "val_transform = transform_selector.get_transform(is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b283513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.249980Z",
     "iopub.status.busy": "2024-09-23T08:45:15.249774Z",
     "iopub.status.idle": "2024-09-23T08:45:15.251813Z",
     "shell.execute_reply": "2024-09-23T08:45:15.251500Z"
    },
    "papermill": {
     "duration": 0.009013,
     "end_time": "2024-09-23T08:45:15.252692",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.243679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32715cca-5a4a-49d5-8fd9-f84da4581523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.263481Z",
     "iopub.status.busy": "2024-09-23T08:45:15.263359Z",
     "iopub.status.idle": "2024-09-23T08:45:15.265396Z",
     "shell.execute_reply": "2024-09-23T08:45:15.265090Z"
    },
    "papermill": {
     "duration": 0.007964,
     "end_time": "2024-09-23T08:45:15.266034",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.258070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습에 사용할 Loss를 선언.\n",
    "# loss_fn = Loss() #cross_entropy_loss\n",
    "loss_fn = FocalLoss(alpha=0.5, gamma=1) #focal_loss\n",
    "# loss_fn = LabelSmoothingLoss(classes=num_classes, smoothing=0.1) #Label_smoothing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10011e8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.273576Z",
     "iopub.status.busy": "2024-09-23T08:45:15.273222Z",
     "iopub.status.idle": "2024-09-23T08:45:15.275735Z",
     "shell.execute_reply": "2024-09-23T08:45:15.275194Z"
    },
    "papermill": {
     "duration": 0.00723,
     "end_time": "2024-09-23T08:45:15.276396",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.269166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 스케줄러 초기화\n",
    "# scheduler_step_size = 15  # 매 15step마다 학습률 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac64a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.284381Z",
     "iopub.status.busy": "2024-09-23T08:45:15.284071Z",
     "iopub.status.idle": "2024-09-24T03:29:39.267094Z",
     "shell.execute_reply": "2024-09-24T03:29:39.266757Z"
    },
    "papermill": {
     "duration": 67463.987789,
     "end_time": "2024-09-24T03:29:39.267796",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.280007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KFold 교차 검증 수행\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_info, train_info['target'])):\n",
    "    print(f'Fold {fold + 1}/{n_splits}')\n",
    "\n",
    "    # train_df와 val_df를 train_idx와 val_idx로 분할\n",
    "    train_df = train_info.iloc[train_idx]\n",
    "    val_df = train_info.iloc[val_idx]\n",
    "\n",
    "    # 학습에 사용할 Model 선언 (매 Fold마다 모델을 초기화)\n",
    "    model_selector = ModelSelector(\n",
    "        model_type='timm', \n",
    "        num_classes=num_classes,\n",
    "        model_name='caformer_s36', \n",
    "        pretrained=True\n",
    "    )\n",
    "    model = model_selector.get_model().to(device)\n",
    "\n",
    "    # optimizer 선언\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.00005, weight_decay=1e-5)\n",
    "    # optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "    # 학습에 사용할 Dataset 선언\n",
    "    train_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=train_df,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    val_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=val_df,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    # 학습에 사용할 DataLoader 선언\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # 한 epoch당 step 수 계산\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    \n",
    "    scheduler_gamma = 0.5  # 학습률을 현재의 30%로 감소\n",
    "    epochs = 50\n",
    "    # StepLR\n",
    "    # 15 epoch마다 학습률을 감소시키는 스케줄러 선언\n",
    "    epochs_per_lr_decay = 30 #25\n",
    "    scheduler_step_size = steps_per_epoch * epochs_per_lr_decay\n",
    "    \n",
    "    # 스케줄러 선언\n",
    "    # scheduler = optim.lr_scheduler.StepLR(\n",
    "    #     optimizer, \n",
    "    #     step_size=scheduler_step_size, \n",
    "    #     gamma=scheduler_gamma\n",
    "    # )\n",
    "    \n",
    "    scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=500, T_mult=1, eta_max=0.1,  T_up=500, gamma=0.5)\n",
    "    \n",
    "    # scheduler = CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, step_size_up=5, step_size_down=None, mode='exp_range', gamma=0.995)\n",
    "    # scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=scheduler_step_size, T_mult=1, eta_max=0.01,  T_up=3, gamma=scheduler_gamma)\n",
    "    # #CosineAnnealingLR\n",
    "    # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=steps_per_epoch * epochs)\n",
    "\n",
    "    # Trainer 선언\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        device=device, \n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn, \n",
    "        epochs=epochs,  # 각 fold마다 동일한 epoch수로 학습\n",
    "        result_path=f\"{save_result_path}/fold_{fold + 1}\"  # 각 fold 결과 저장\n",
    "    )\n",
    "\n",
    "    # 모델 학습 및 결과 저장\n",
    "    fold_result = trainer.train()\n",
    "    fold_results.append(fold_result)\n",
    "\n",
    "# 각 Fold의 결과를 기반으로 평균 성능 계산\n",
    "average_performance = sum(fold_results) / len(fold_results)\n",
    "print(f'KFold 평균 성능: {average_performance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb553f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴드 수 및 모델 저장 경로 설정\n",
    "n_folds = 5\n",
    "fold_model_paths = [f\"./train_result_code1_ca/fold_{fold + 1}/best_model.pt\" for fold in range(n_folds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcbf228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold 교차 검증 수행\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_info, train_info['target'])):\n",
    "    print(f'Fold {fold + 1}/{n_splits}')\n",
    "\n",
    "    # train_df와 val_df를 train_idx와 val_idx로 분할\n",
    "    train_df = train_info.iloc[train_idx]\n",
    "    val_df = train_info.iloc[val_idx]\n",
    "\n",
    "    # 학습에 사용할 Model 선언 (매 Fold마다 모델을 초기화)\n",
    "    model_selector = ModelSelector(\n",
    "        model_type='timm', \n",
    "        num_classes=num_classes,\n",
    "        model_name='caformer_s36', \n",
    "        pretrained=True\n",
    "    )\n",
    "    model = model_selector.get_model().to(device)\n",
    "\n",
    "    # optimizer 선언\n",
    "    # optimizer = optim.AdamW(model.parameters(), lr=0.00005, weight_decay=1e-5)\n",
    "    optimizer = RAdam(params, lr=args.lr, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=False)\n",
    "    \n",
    "    # 학습에 사용할 Dataset 선언\n",
    "    train_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=train_df,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    val_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=val_df,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    # 학습에 사용할 DataLoader 선언\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # 한 epoch당 step 수 계산\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    \n",
    "    scheduler_gamma = 0.5  # 학습률을 현재의 30%로 감소\n",
    "    epochs = 50\n",
    "    # StepLR\n",
    "    # 15 epoch마다 학습률을 감소시키는 스케줄러 선언\n",
    "    epochs_per_lr_decay = 30 #25\n",
    "    scheduler_step_size = steps_per_epoch * epochs_per_lr_decay\n",
    "    \n",
    "    # 스케줄러 선언\n",
    "    # scheduler = optim.lr_scheduler.StepLR(\n",
    "    #     optimizer, \n",
    "    #     step_size=scheduler_step_size, \n",
    "    #     gamma=scheduler_gamma\n",
    "    # )\n",
    "    \n",
    "    scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=500, T_mult=1, eta_max=0.1,  T_up=500, gamma=0.5)\n",
    "    \n",
    "    # scheduler = CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, step_size_up=5, step_size_down=None, mode='exp_range', gamma=0.995)\n",
    "    # scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=scheduler_step_size, T_mult=1, eta_max=0.01,  T_up=3, gamma=scheduler_gamma)\n",
    "    # #CosineAnnealingLR\n",
    "    # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=steps_per_epoch * epochs)\n",
    "\n",
    "    # Trainer 선언\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        device=device, \n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn, \n",
    "        epochs=epochs,  # 각 fold마다 동일한 epoch수로 학습\n",
    "        result_path=f\"{save_result_path}/fold_{fold + 1}\"  # 각 fold 결과 저장\n",
    "    )\n",
    "\n",
    "    # 모델 학습 및 결과 저장\n",
    "    fold_result = trainer.train()\n",
    "    fold_results.append(fold_result)\n",
    "\n",
    "# 각 Fold의 결과를 기반으로 평균 성능 계산\n",
    "average_performance = sum(fold_results) / len(fold_results)\n",
    "print(f'KFold 평균 성능: {average_performance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b28774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴드 수 및 모델 저장 경로 설정\n",
    "n_folds = 5\n",
    "fold_model_paths = [f\"./train_result_code2_ca/fold_{fold + 1}/best_model.pt\" for fold in range(n_folds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11087088-9b1f-4f7d-8eb5-72008cc88a50",
   "metadata": {
    "papermill": {
     "duration": 3.241872,
     "end_time": "2024-09-24T03:29:45.651368",
     "exception": false,
     "start_time": "2024-09-24T03:29:42.409496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087a35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:29:58.443983Z",
     "iopub.status.busy": "2024-09-24T03:29:58.443490Z",
     "iopub.status.idle": "2024-09-24T03:29:58.446024Z",
     "shell.execute_reply": "2024-09-24T03:29:58.445749Z"
    },
    "papermill": {
     "duration": 3.088871,
     "end_time": "2024-09-24T03:29:58.446568",
     "exception": false,
     "start_time": "2024-09-24T03:29:55.357697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(fold_model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59e016d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:04.844866Z",
     "iopub.status.busy": "2024-09-24T03:30:04.844442Z",
     "iopub.status.idle": "2024-09-24T03:30:04.847989Z",
     "shell.execute_reply": "2024-09-24T03:30:04.847751Z"
    },
    "papermill": {
     "duration": 3.306368,
     "end_time": "2024-09-24T03:30:04.848569",
     "exception": false,
     "start_time": "2024-09-24T03:30:01.542201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 저장된 모델을 불러와서 앙상블을 수행하는 함수\n",
    "def ensemble_predict_folds(\n",
    "    fold_model_paths: list, \n",
    "    device: torch.device, \n",
    "    test_loader: DataLoader\n",
    "    ):\n",
    "    models = []\n",
    "    \n",
    "    # 각 폴드의 베스트 모델 불러오기\n",
    "    for fold_path in fold_model_paths:\n",
    "        # 모델 초기화 및 로드\n",
    "        model = ModelSelector(\n",
    "            model_type='timm', \n",
    "            num_classes=num_classes,\n",
    "            model_name='caformer_s36', \n",
    "            pretrained=False\n",
    "        ).get_model().to(device)\n",
    "        model.load_state_dict(torch.load(fold_path, map_location=device))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            # 이미지를 GPU 또는 CPU로 이동\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # 폴드별 예측 수행\n",
    "            fold_preds = []\n",
    "            for model in models:\n",
    "                logits = model(images)\n",
    "                logits = F.softmax(logits, dim=1)  # 확률값으로 변환\n",
    "                fold_preds.append(logits)\n",
    "            \n",
    "            # 폴드별 예측 결과 평균\n",
    "            avg_preds = torch.mean(torch.stack(fold_preds), dim=0)\n",
    "            final_preds = avg_preds.argmax(dim=1)\n",
    "            \n",
    "            # 예측 결과 저장\n",
    "            predictions.extend(final_preds.cpu().detach().numpy())\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b407c24c-785d-4ffc-b17b-84ae7dc4ecae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:11.244864Z",
     "iopub.status.busy": "2024-09-24T03:30:11.244632Z",
     "iopub.status.idle": "2024-09-24T03:30:11.246732Z",
     "shell.execute_reply": "2024-09-24T03:30:11.246474Z"
    },
    "papermill": {
     "duration": 3.300085,
     "end_time": "2024-09-24T03:30:11.247343",
     "exception": false,
     "start_time": "2024-09-24T03:30:07.947258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추론 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "testdata_dir = \"../data/test\"\n",
    "testdata_info_file = \"../data/test.csv\"\n",
    "save_result_path = \"../train_result_code8_ca_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbb89c12-3b5d-4647-a8c2-83650dce6281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:17.675559Z",
     "iopub.status.busy": "2024-09-24T03:30:17.675200Z",
     "iopub.status.idle": "2024-09-24T03:30:17.681593Z",
     "shell.execute_reply": "2024-09-24T03:30:17.681160Z"
    },
    "papermill": {
     "duration": 3.300408,
     "end_time": "2024-09-24T03:30:17.682597",
     "exception": false,
     "start_time": "2024-09-24T03:30:14.382189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추론 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "test_info = pd.read_csv(testdata_info_file)\n",
    "\n",
    "# 총 class 수.\n",
    "num_classes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecec8773-6045-401e-b307-0a9758374c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:24.370899Z",
     "iopub.status.busy": "2024-09-24T03:30:24.370677Z",
     "iopub.status.idle": "2024-09-24T03:30:24.374845Z",
     "shell.execute_reply": "2024-09-24T03:30:24.374341Z"
    },
    "papermill": {
     "duration": 3.279078,
     "end_time": "2024-09-24T03:30:24.375845",
     "exception": false,
     "start_time": "2024-09-24T03:30:21.096767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추론에 사용할 Transform을 선언.\n",
    "transform_selector = TransformSelector(\n",
    "    transform_type = \"albumentations\"\n",
    ")\n",
    "test_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "# 추론에 사용할 Dataset을 선언.\n",
    "test_dataset = CustomDataset(\n",
    "    root_dir=testdata_dir,\n",
    "    info_df=test_info,\n",
    "    transform=test_transform,\n",
    "    is_inference=True\n",
    ")\n",
    "\n",
    "# 추론에 사용할 DataLoader를 선언.\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb15fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:30.698339Z",
     "iopub.status.busy": "2024-09-24T03:30:30.697897Z",
     "iopub.status.idle": "2024-09-24T03:31:32.721371Z",
     "shell.execute_reply": "2024-09-24T03:31:32.720776Z"
    },
    "papermill": {
     "duration": 65.245117,
     "end_time": "2024-09-24T03:31:32.722092",
     "exception": false,
     "start_time": "2024-09-24T03:30:27.476975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 폴드별 저장된 모델을 사용한 앙상블 추론 실행\n",
    "predictions = ensemble_predict_folds(\n",
    "    fold_model_paths=fold_model_paths, \n",
    "    device=device, \n",
    "    test_loader=test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96c889-2423-42b2-8c3c-4b1d364ece71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:31:38.832057Z",
     "iopub.status.busy": "2024-09-24T03:31:38.831586Z",
     "iopub.status.idle": "2024-09-24T03:31:38.846518Z",
     "shell.execute_reply": "2024-09-24T03:31:38.846294Z"
    },
    "papermill": {
     "duration": 3.057988,
     "end_time": "2024-09-24T03:31:38.847111",
     "exception": false,
     "start_time": "2024-09-24T03:31:35.789123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모든 클래스에 대한 예측 결과를 하나의 문자열로 합침\n",
    "test_info['target'] = predictions\n",
    "test_info = test_info.reset_index().rename(columns={\"index\": \"ID\"})\n",
    "test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4efd2f6-d74a-491b-a7b1-fd7cf96f45a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:31:45.295500Z",
     "iopub.status.busy": "2024-09-24T03:31:45.295248Z",
     "iopub.status.idle": "2024-09-24T03:31:45.306856Z",
     "shell.execute_reply": "2024-09-24T03:31:45.306350Z"
    },
    "papermill": {
     "duration": 3.237238,
     "end_time": "2024-09-24T03:31:45.307962",
     "exception": false,
     "start_time": "2024-09-24T03:31:42.070724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 예측 결과를 CSV 파일로 저장\n",
    "test_info.to_csv(\"output_code8_ca_v2.csv\", index=False)\n",
    "print(f\"추론 결과가 output_code8_ca_v2.csv 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac79e3df-e5c3-4a49-b37e-0dea1300c317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:31:51.903078Z",
     "iopub.status.busy": "2024-09-24T03:31:51.902855Z",
     "iopub.status.idle": "2024-09-24T03:31:51.906756Z",
     "shell.execute_reply": "2024-09-24T03:31:51.906229Z"
    },
    "papermill": {
     "duration": 3.433788,
     "end_time": "2024-09-24T03:31:51.907872",
     "exception": false,
     "start_time": "2024-09-24T03:31:48.474084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def visualize_gradcam(\n",
    "#         model: torch.nn.Module,\n",
    "#         device: torch.device,\n",
    "#         dataloader: DataLoader,\n",
    "#         target_layer: str,\n",
    "#         image_index: int\n",
    "#     ):\n",
    "\n",
    "#     # Grad-CAM 추출기를 초기화합니다.\n",
    "#     cam_extractor = GradCAM(model, target_layer)\n",
    "    \n",
    "#     model.eval()  # 모델을 평가 모드로 설정합니다.\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # 시각화를 위한 Figure를 생성합니다.\n",
    "    \n",
    "#     # 데이터 로더에서 배치를 반복합니다.\n",
    "#     current_index = 0\n",
    "#     for inputs in dataloader:\n",
    "#         inputs = inputs.to(device)  # 입력 이미지를 장치로 이동합니다.\n",
    "        \n",
    "#         outputs = model(inputs)  # 모델을 통해 예측을 수행합니다.\n",
    "#         _, preds = torch.max(outputs, 1)  # 예측된 클래스 인덱스를 가져옵니다.\n",
    "        \n",
    "#         # 배치 내의 각 이미지에 대해 처리합니다.\n",
    "#         for j in range(inputs.size()[0]):\n",
    "#             if current_index == image_index:\n",
    "#                 # CAM을 가져옵니다.\n",
    "#                 cam = cam_extractor(preds[j].item(), outputs[j].unsqueeze(0))[0]\n",
    "#                 # CAM을 1채널로 변환합니다.\n",
    "#                 cam = cam.mean(dim=0).cpu().numpy()\n",
    "                \n",
    "#                 # CAM을 원본 이미지 크기로 리사이즈합니다.\n",
    "#                 cam = cv2.resize(cam, (inputs[j].shape[2], inputs[j].shape[1]))\n",
    "                \n",
    "#                 # CAM을 정규화합니다.\n",
    "#                 cam = (cam - cam.min()) / (cam.max() - cam.min())  # 정규화\n",
    "#                 ㅈ\n",
    "#                 # CAM을 0-255 범위로 변환합니다.\n",
    "#                 cam = np.uint8(255 * cam)\n",
    "#                 # 컬러맵을 적용하여 RGB 이미지로 변환합니다.\n",
    "#                 cam = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "#                 cam = cv2.cvtColor(cam, cv2.COLOR_BGR2RGB)  # BGR에서 RGB로 변환\n",
    "                \n",
    "#                 # 입력 이미지가 1채널 또는 3채널인지 확인하고 처리합니다.\n",
    "#                 input_image = inputs[j].cpu().numpy().transpose((1, 2, 0))\n",
    "#                 if input_image.shape[2] == 1:  # 1채널 이미지인 경우\n",
    "#                     input_image = np.squeeze(input_image, axis=2)  # (H, W, 1) -> (H, W)\n",
    "#                     input_image = np.stack([input_image] * 3, axis=-1)  # (H, W) -> (H, W, 3)로 변환하여 RGB처럼 만듭니다.\n",
    "#                 else:  # 3채널 이미지인 경우\n",
    "#                     input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "#                     input_image = (input_image * 255).astype(np.uint8)  # 정규화된 이미지를 8비트 이미지로 변환합니다.\n",
    "                \n",
    "#                 # 오리지널 이미지\n",
    "#                 axes[0].imshow(input_image)\n",
    "#                 axes[0].set_title(\"Original Image\")\n",
    "#                 axes[0].axis('off')\n",
    "                \n",
    "#                 # Grad-CAM 이미지\n",
    "#                 axes[1].imshow(cam)\n",
    "#                 axes[1].set_title(\"Grad-CAM Image\")\n",
    "#                 axes[1].axis('off')\n",
    "                \n",
    "#                 # 오버레이된 이미지 생성\n",
    "#                 overlay = cv2.addWeighted(input_image, 0.5, cam, 0.5, 0)\n",
    "#                 axes[2].imshow(overlay)\n",
    "#                 axes[2].set_title(\"Overlay Image\")\n",
    "#                 axes[2].axis('off')\n",
    "                \n",
    "#                 plt.show()  # 시각화를 표시합니다.\n",
    "#                 return\n",
    "#             current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91cd0879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:31:58.138205Z",
     "iopub.status.busy": "2024-09-24T03:31:58.137984Z",
     "iopub.status.idle": "2024-09-24T03:31:58.140448Z",
     "shell.execute_reply": "2024-09-24T03:31:58.140110Z"
    },
    "papermill": {
     "duration": 3.131287,
     "end_time": "2024-09-24T03:31:58.141188",
     "exception": false,
     "start_time": "2024-09-24T03:31:55.009901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ace35397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:32:04.566095Z",
     "iopub.status.busy": "2024-09-24T03:32:04.565877Z",
     "iopub.status.idle": "2024-09-24T03:32:04.568768Z",
     "shell.execute_reply": "2024-09-24T03:32:04.568162Z"
    },
    "papermill": {
     "duration": 3.284854,
     "end_time": "2024-09-24T03:32:04.569484",
     "exception": false,
     "start_time": "2024-09-24T03:32:01.284630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target_layer = 'layer4.1.act2'\n",
    "\n",
    "# # Grad-CAM 시각화 실행 (예: 인덱스 3의 이미지를 시각화)\n",
    "\n",
    "# image_index = 3\n",
    "\n",
    "# visualize_gradcam(model.model, device, test_loader, target_layer=target_layer, image_index=image_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67616.64487,
   "end_time": "2024-09-24T03:32:08.718839",
   "environment_variables": {},
   "exception": null,
   "input_path": "code8_ca_v2.ipynb",
   "output_path": "code8_ca_v2_result.ipynb",
   "parameters": {},
   "start_time": "2024-09-23T08:45:12.073969",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
