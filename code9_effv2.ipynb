{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af8a2c0-45fe-4d13-bebd-0dca87a7b71f",
   "metadata": {
    "papermill": {
     "duration": 0.003356,
     "end_time": "2024-09-20T15:15:24.224884",
     "exception": false,
     "start_time": "2024-09-20T15:15:24.221528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c611c8-2226-433c-bf5f-343cc0b094af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:24.236987Z",
     "iopub.status.busy": "2024-09-20T15:15:24.236809Z",
     "iopub.status.idle": "2024-09-20T15:15:26.191986Z",
     "shell.execute_reply": "2024-09-20T15:15:26.191502Z"
    },
    "papermill": {
     "duration": 1.959609,
     "end_time": "2024-09-20T15:15:26.193089",
     "exception": false,
     "start_time": "2024-09-20T15:15:24.233480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 필요 library들을 import합니다.\n",
    "import os\n",
    "from typing import Tuple, Any, Callable, List, Optional, Union\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from torchcam.methods import GradCAM\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28d0864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.205531Z",
     "iopub.status.busy": "2024-09-20T15:15:26.205317Z",
     "iopub.status.idle": "2024-09-20T15:15:26.234289Z",
     "shell.execute_reply": "2024-09-20T15:15:26.233960Z"
    },
    "papermill": {
     "duration": 0.038972,
     "end_time": "2024-09-20T15:15:26.235092",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.196120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e9123b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.241375Z",
     "iopub.status.busy": "2024-09-20T15:15:26.241249Z",
     "iopub.status.idle": "2024-09-20T15:15:26.244249Z",
     "shell.execute_reply": "2024-09-20T15:15:26.244040Z"
    },
    "papermill": {
     "duration": 0.007367,
     "end_time": "2024-09-20T15:15:26.245380",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.238013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d69e6a-a719-4a97-92ca-6354c873313f",
   "metadata": {
    "papermill": {
     "duration": 0.002761,
     "end_time": "2024-09-20T15:15:26.251213",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.248452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f97229-e29f-479d-abab-0db8219d1803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.257261Z",
     "iopub.status.busy": "2024-09-20T15:15:26.257134Z",
     "iopub.status.idle": "2024-09-20T15:15:26.260720Z",
     "shell.execute_reply": "2024-09-20T15:15:26.260431Z"
    },
    "papermill": {
     "duration": 0.007613,
     "end_time": "2024-09-20T15:15:26.261587",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.253974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        root_dir: str, \n",
    "        info_df: pd.DataFrame, \n",
    "        transform: Callable,\n",
    "        is_inference: bool = False\n",
    "    ):\n",
    "        # 데이터셋의 기본 경로, 이미지 변환 방법, 이미지 경로 및 레이블을 초기화합니다.\n",
    "        self.root_dir = root_dir  # 이미지 파일들이 저장된 기본 디렉토리\n",
    "        self.transform = transform  # 이미지에 적용될 변환 처리\n",
    "        self.is_inference = is_inference # 추론인지 확인\n",
    "        self.image_paths = info_df['image_path'].tolist()  # 이미지 파일 경로 목록\n",
    "        \n",
    "        if not self.is_inference:\n",
    "            self.targets = info_df['target'].tolist()  # 각 이미지에 대한 레이블 목록\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # 데이터셋의 총 이미지 수를 반환합니다.\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[Tuple[torch.Tensor, int], torch.Tensor]:\n",
    "        # 주어진 인덱스에 해당하는 이미지를 로드하고 변환을 적용한 후, 이미지와 레이블을 반환합니다.\n",
    "        img_path = os.path.join(self.root_dir, self.image_paths[index])  # 이미지 경로 조합\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)  # 이미지를 BGR 컬러 포맷의 numpy array로 읽어옵니다.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR 포맷을 RGB 포맷으로 변환합니다.\n",
    "        image = self.transform(image)  # 설정된 이미지 변환을 적용합니다.\n",
    "\n",
    "        if self.is_inference:\n",
    "            return image\n",
    "        else:\n",
    "            target = self.targets[index]  # 해당 이미지의 레이블\n",
    "            return image, target  # 변환된 이미지와 레이블을 튜플 형태로 반환합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07d2d0-9585-45ce-8ece-4f69b98f6dd4",
   "metadata": {
    "papermill": {
     "duration": 0.00274,
     "end_time": "2024-09-20T15:15:26.267139",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.264399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transform Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1855c1-cf13-476d-aabd-d78e9e082ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.273463Z",
     "iopub.status.busy": "2024-09-20T15:15:26.273265Z",
     "iopub.status.idle": "2024-09-20T15:15:26.276568Z",
     "shell.execute_reply": "2024-09-20T15:15:26.276267Z"
    },
    "papermill": {
     "duration": 0.007336,
     "end_time": "2024-09-20T15:15:26.277179",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.269843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorchvisionTransform:\n",
    "    def __init__(self, is_train: bool = True):\n",
    "        # 공통 변환 설정: 이미지 리사이즈, 텐서 변환, 정규화\n",
    "        common_transforms = [\n",
    "            transforms.Resize((224, 224)),  # 이미지를 224x224 크기로 리사이즈\n",
    "            transforms.ToTensor(),  # 이미지를 PyTorch 텐서로 변환\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n",
    "        ]\n",
    "        \n",
    "        if is_train:\n",
    "            # 훈련용 변환: 랜덤 수평 뒤집기, 랜덤 회전, 색상 조정 추가\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.RandomHorizontalFlip(p=0.5),  # 50% 확률로 이미지를 수평 뒤집기\n",
    "                    transforms.RandomRotation(15),  # 최대 15도 회전\n",
    "                    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # 밝기 및 대비 조정\n",
    "                ] + common_transforms\n",
    "            )\n",
    "        else:\n",
    "            # 검증/테스트용 변환: 공통 변환만 적용\n",
    "            self.transform = transforms.Compose(common_transforms)\n",
    "\n",
    "    def __call__(self, image: np.ndarray) -> torch.Tensor:\n",
    "        image = Image.fromarray(image)  # numpy 배열을 PIL 이미지로 변환\n",
    "        \n",
    "        transformed = self.transform(image)  # 설정된 변환을 적용\n",
    "        \n",
    "        return transformed  # 변환된 이미지 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsharpMask(A.ImageOnlyTransform):\n",
    "    def __init__(self, kernel_size=5, sigma=1.0, amount=1.0, threshold=0, always_apply=False, p=1.0):\n",
    "        super(UnsharpMask, self).__init__(always_apply, p)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.amount = amount\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        return self.unsharp_mask(image)\n",
    "\n",
    "    def unsharp_mask(self, image):\n",
    "        blurred = cv2.GaussianBlur(image, (self.kernel_size, self.kernel_size), self.sigma)\n",
    "        sharpened = cv2.addWeighted(image, 1.0 + self.amount, blurred, -self.amount, 0)\n",
    "        if self.threshold > 0:\n",
    "            low_contrast_mask = np.absolute(image - blurred) < self.threshold\n",
    "            np.copyto(sharpened, image, where=low_contrast_mask)\n",
    "        return sharpened    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a683988-0f73-4e43-907b-0d5209550abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.283239Z",
     "iopub.status.busy": "2024-09-20T15:15:26.283152Z",
     "iopub.status.idle": "2024-09-20T15:15:26.286917Z",
     "shell.execute_reply": "2024-09-20T15:15:26.286612Z"
    },
    "papermill": {
     "duration": 0.007625,
     "end_time": "2024-09-20T15:15:26.287535",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.279910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AlbumentationsTransform:\n",
    "    def __init__(self, is_train: bool = True):\n",
    "        # 공통 변환 설정: 이미지 리사이즈, 정규화, 텐서 변환\n",
    "        common_transforms = [\n",
    "            A.Resize(224, 224),  # 이미지를 224x224 크기로 리사이즈\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 정규화\n",
    "            ToTensorV2()  # albumentations에서 제공하는 PyTorch 텐서 변환\n",
    "        ]\n",
    "        \n",
    "        if is_train:\n",
    "            # 훈련용 변환: 랜덤 수평 뒤집기, 랜덤 회전, 랜덤 밝기 및 대비 조정 추가\n",
    "            self.transform = A.Compose(\n",
    "                [\n",
    "                    A.HorizontalFlip(p=0.7),  # 수평 뒤집기\n",
    "                    A.Rotate(limit=20, p=0.5),  # Rotation (회전 범위 제한)\n",
    "                    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.1), contrast_limit=(-0.2, 0.2), p=0.7),  # 밝기 및 대비 조정\n",
    "                    UnsharpMask(kernel_size=3, sigma=1.0, amount=1.0, threshold=10, p=1.0),  # 언샤프 마스크 적용  \n",
    "                    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.4), # 블럭 추가\n",
    "                    A.GridDistortion(always_apply=False, p=1, num_steps=1, distort_limit=(-0.03, 0.05), interpolation=2, border_mode=0, value=(0, 0, 0), mask_value=None),                    \n",
    "                    A.ElasticTransform(alpha=0.3, sigma=10, alpha_affine=5, p=0.3),  # Elastic Transform (강도 조정)\n",
    "                    # A.OneOf([A.Emboss(p=0.5), A.Sharpen(p=0.5)], p=0.5),  # Emboss & Sharpen\n",
    "                    # A.GaussianBlur(blur_limit=(3, 5), p=0.4), # 약간의 블러 추가                           \n",
    "                    # A.Affine(scale=(0.95, 1.05), shear=(-3, 3), p=0.5),  # Affine (스케일 및 쉬어 변형)           \n",
    "                ] + common_transforms\n",
    "            )\n",
    "        else:\n",
    "            # 검증/테스트용 변환: 공통 변환만 적용\n",
    "            self.transform = A.Compose(common_transforms)\n",
    "\n",
    "    def __call__(self, image) -> torch.Tensor:\n",
    "        # 이미지가 NumPy 배열인지 확인\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            raise TypeError(\"Image should be a NumPy array (OpenCV format).\")\n",
    "        \n",
    "        # 이미지에 변환 적용 및 결과 반환\n",
    "        transformed = self.transform(image=image)  # 이미지에 설정된 변환을 적용\n",
    "        \n",
    "        return transformed['image']  # 변환된 이미지의 텐서를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82f3416-86f2-430f-9260-d23904e757e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.293854Z",
     "iopub.status.busy": "2024-09-20T15:15:26.293487Z",
     "iopub.status.idle": "2024-09-20T15:15:26.295820Z",
     "shell.execute_reply": "2024-09-20T15:15:26.295621Z"
    },
    "papermill": {
     "duration": 0.006155,
     "end_time": "2024-09-20T15:15:26.296437",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.290282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformSelector:\n",
    "    \"\"\"\n",
    "    이미지 변환 라이브러리를 선택하기 위한 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, transform_type: str):\n",
    "\n",
    "        # 지원하는 변환 라이브러리인지 확인\n",
    "        if transform_type in [\"torchvision\", \"albumentations\"]:\n",
    "            self.transform_type = transform_type\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown transformation library specified.\")\n",
    "\n",
    "    def get_transform(self, is_train: bool):\n",
    "        \n",
    "        # 선택된 라이브러리에 따라 적절한 변환 객체를 생성\n",
    "        if self.transform_type == 'torchvision':\n",
    "            transform = TorchvisionTransform(is_train=is_train)\n",
    "        \n",
    "        elif self.transform_type == 'albumentations':\n",
    "            transform = AlbumentationsTransform(is_train=is_train)\n",
    "        \n",
    "        return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938bcb2-9257-49cb-8d05-dd4a7bb25665",
   "metadata": {
    "papermill": {
     "duration": 0.002783,
     "end_time": "2024-09-20T15:15:26.302078",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.299295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f16fb24a-8d34-4ed6-8a33-2d153d12d190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.308128Z",
     "iopub.status.busy": "2024-09-20T15:15:26.307987Z",
     "iopub.status.idle": "2024-09-20T15:15:26.311252Z",
     "shell.execute_reply": "2024-09-20T15:15:26.311010Z"
    },
    "papermill": {
     "duration": 0.007464,
     "end_time": "2024-09-20T15:15:26.312314",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.304850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    간단한 CNN 아키텍처를 정의하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # 순전파 함수 정의\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91493ca-c5c2-4950-916a-cc4304c7ad4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.322648Z",
     "iopub.status.busy": "2024-09-20T15:15:26.322522Z",
     "iopub.status.idle": "2024-09-20T15:15:26.325692Z",
     "shell.execute_reply": "2024-09-20T15:15:26.325284Z"
    },
    "papermill": {
     "duration": 0.008896,
     "end_time": "2024-09-20T15:15:26.326274",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.317378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorchvisionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Torchvision에서 제공하는 사전 훈련된 모델을 사용하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str, \n",
    "        num_classes: int, \n",
    "        pretrained: bool\n",
    "    ):\n",
    "        super(TorchvisionModel, self).__init__()\n",
    "        self.model = models.__dict__[model_name](pretrained=pretrained)\n",
    "        \n",
    "        # 모델의 최종 분류기 부분을 사용자 정의 클래스 수에 맞게 조정\n",
    "        if 'fc' in dir(self.model):\n",
    "            num_ftrs = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        elif 'classifier' in dir(self.model):\n",
    "            num_ftrs = self.model.classifier[-1].in_features\n",
    "            self.model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f28c8e4f-a914-4b12-982e-d4a58863c717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.332382Z",
     "iopub.status.busy": "2024-09-20T15:15:26.332238Z",
     "iopub.status.idle": "2024-09-20T15:15:26.334844Z",
     "shell.execute_reply": "2024-09-20T15:15:26.334461Z"
    },
    "papermill": {
     "duration": 0.006349,
     "end_time": "2024-09-20T15:15:26.335406",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.329057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Timm 라이브러리를 사용하여 다양한 사전 훈련된 모델을 제공하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str, \n",
    "        num_classes: int, \n",
    "        pretrained: bool\n",
    "    ):\n",
    "        super(TimmModel, self).__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2da081-9010-431d-a049-835d7bbea4a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.341650Z",
     "iopub.status.busy": "2024-09-20T15:15:26.341435Z",
     "iopub.status.idle": "2024-09-20T15:15:26.344343Z",
     "shell.execute_reply": "2024-09-20T15:15:26.343977Z"
    },
    "papermill": {
     "duration": 0.006699,
     "end_time": "2024-09-20T15:15:26.344902",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.338203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelSelector:\n",
    "    \"\"\"\n",
    "    사용할 모델 유형을 선택하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_type: str, \n",
    "        num_classes: int, \n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        # 모델 유형에 따라 적절한 모델 객체를 생성\n",
    "        if model_type == 'simple':\n",
    "            self.model = SimpleCNN(num_classes=num_classes)\n",
    "        \n",
    "        elif model_type == 'torchvision':\n",
    "            self.model = TorchvisionModel(num_classes=num_classes, **kwargs)\n",
    "        \n",
    "        elif model_type == 'timm':\n",
    "            self.model = TimmModel(num_classes=num_classes, **kwargs)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown model type specified.\")\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "\n",
    "        # 생성된 모델 객체 반환\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2977c7b-bc39-48f7-8155-ef6b6a03d6f8",
   "metadata": {
    "papermill": {
     "duration": 0.002721,
     "end_time": "2024-09-20T15:15:26.350344",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.347623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1b52141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.356420Z",
     "iopub.status.busy": "2024-09-20T15:15:26.356153Z",
     "iopub.status.idle": "2024-09-20T15:15:26.359062Z",
     "shell.execute_reply": "2024-09-20T15:15:26.358679Z"
    },
    "papermill": {
     "duration": 0.006567,
     "end_time": "2024-09-20T15:15:26.359636",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.353069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes: int, smoothing: float = 0.1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "\n",
    "    def forward(self, x: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        log_probs = F.log_softmax(x, dim=-1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(log_probs)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c51e6c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.365967Z",
     "iopub.status.busy": "2024-09-20T15:15:26.365736Z",
     "iopub.status.idle": "2024-09-20T15:15:26.368555Z",
     "shell.execute_reply": "2024-09-20T15:15:26.368265Z"
    },
    "papermill": {
     "duration": 0.006843,
     "end_time": "2024-09-20T15:15:26.369257",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.362414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Cross Entropy Loss 계산\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        # 예측 확률 계산\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        # Focal Loss 계산\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97471eb3-a979-4fb3-b976-6c3177c79f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.375444Z",
     "iopub.status.busy": "2024-09-20T15:15:26.375298Z",
     "iopub.status.idle": "2024-09-20T15:15:26.377420Z",
     "shell.execute_reply": "2024-09-20T15:15:26.377140Z"
    },
    "papermill": {
     "duration": 0.005862,
     "end_time": "2024-09-20T15:15:26.377988",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.372126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    모델의 손실함수를 계산하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        outputs: torch.Tensor, \n",
    "        targets: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "    \n",
    "        return self.loss_fn(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=False):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        \n",
    "        self.degenerated_to_sgd = degenerated_to_sgd\n",
    "        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n",
    "            for param in params:\n",
    "                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n",
    "                    param['buffer'] = [[None, None, None] for _ in range(10)]\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, buffer=[[None, None, None] for _ in range(10)])\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = group['buffer'][int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    elif self.degenerated_to_sgd:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = -1\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "                elif step_size > 0:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e3d21-5ab8-41b0-aa5c-e62ace8dc6a6",
   "metadata": {
    "papermill": {
     "duration": 0.002798,
     "end_time": "2024-09-20T15:15:26.383549",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.380751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a90c673-6672-4066-a9ec-9975d7842be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.389603Z",
     "iopub.status.busy": "2024-09-20T15:15:26.389497Z",
     "iopub.status.idle": "2024-09-20T15:15:26.396351Z",
     "shell.execute_reply": "2024-09-20T15:15:26.396071Z"
    },
    "papermill": {
     "duration": 0.010705,
     "end_time": "2024-09-20T15:15:26.397027",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.386322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        device: torch.device, \n",
    "        train_loader: DataLoader, \n",
    "        val_loader: DataLoader, \n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler: optim.lr_scheduler,\n",
    "        loss_fn: torch.nn.modules.loss._Loss, \n",
    "        epochs: int,\n",
    "        result_path: str\n",
    "    ):\n",
    "        # 클래스 초기화: 모델, 디바이스, 데이터 로더 등 설정\n",
    "        self.model = model  # 훈련할 모델\n",
    "        self.device = device  # 연산을 수행할 디바이스 (CPU or GPU)\n",
    "        self.train_loader = train_loader  # 훈련 데이터 로더\n",
    "        self.val_loader = val_loader  # 검증 데이터 로더\n",
    "        self.optimizer = optimizer  # 최적화 알고리즘\n",
    "        self.scheduler = scheduler  # 학습률 스케줄러\n",
    "        self.loss_fn = loss_fn  # 손실 함수\n",
    "        self.epochs = epochs  # 총 훈련 에폭 수\n",
    "        self.result_path = result_path  # 모델 저장 경로\n",
    "        self.best_models = []  # 가장 좋은 상위 3개 모델의 정보를 저장할 리스트\n",
    "        self.lowest_loss = float('inf')  # 가장 낮은 Loss를 저장할 변수\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        # 모델 저장 경로 설정\n",
    "        os.makedirs(self.result_path, exist_ok=True)\n",
    "\n",
    "        # 현재 에폭 모델 저장\n",
    "        current_model_path = os.path.join(self.result_path, f'model_epoch_{epoch}_loss_{loss:.4f}.pt')\n",
    "        torch.save(self.model.state_dict(), current_model_path)\n",
    "\n",
    "        # 최상위 3개 모델 관리\n",
    "        self.best_models.append((loss, epoch, current_model_path))\n",
    "        self.best_models.sort()\n",
    "        if len(self.best_models) > 3:\n",
    "            _, _, path_to_remove = self.best_models.pop(-1)  # 가장 높은 손실 모델 삭제\n",
    "            if os.path.exists(path_to_remove):\n",
    "                os.remove(path_to_remove)\n",
    "\n",
    "        # 가장 낮은 손실의 모델 저장\n",
    "        if loss < self.lowest_loss:\n",
    "            self.lowest_loss = loss\n",
    "            best_model_path = os.path.join(self.result_path, 'best_model.pt')\n",
    "            torch.save(self.model.state_dict(), best_model_path)\n",
    "            print(f\"Save {epoch}epoch result. Loss = {loss:.4f}\")\n",
    "\n",
    "    def train_epoch(self) -> float:\n",
    "        # 한 에폭 동안의 훈련을 진행\n",
    "        self.model.train()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "                \n",
    "        progress_bar = tqdm(self.train_loader, desc=\"Training\", leave=False)\n",
    "\n",
    "        for images, targets in progress_bar:\n",
    "            images, targets = images.to(self.device), targets.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)  # 예측된 클래스\n",
    "            correct_predictions += (preds == targets).sum().item()  # 맞춘 예측 개수\n",
    "            total_samples += targets.size(0)  # 전체 샘플 수\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "            \n",
    "        accuracy = correct_predictions / total_samples * 100  # 정확도 계산\n",
    "        print(f\"Train Accuracy: {accuracy:.2f}%\")            \n",
    "\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    def validate(self) -> float:\n",
    "        # 모델의 검증을 진행\n",
    "        self.model.eval()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        progress_bar = tqdm(self.val_loader, desc=\"Validating\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in progress_bar:\n",
    "                images, targets = images.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # 정확도 계산\n",
    "                _, preds = torch.max(outputs, 1)  # 예측된 클래스\n",
    "                correct_predictions += (preds == targets).sum().item()  # 맞춘 예측 개수\n",
    "                total_samples += targets.size(0)  # 전체 샘플 수                \n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        accuracy = correct_predictions / total_samples * 100  # 정확도 계산\n",
    "        print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        return total_loss / len(self.val_loader)\n",
    "\n",
    "    def train(self) -> float:\n",
    "        # 전체 훈련 과정을 관리\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "\n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss = self.validate()\n",
    "\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Learning Rate: {current_lr:.6f}\\n\")\n",
    "\n",
    "            self.save_model(epoch, val_loss)\n",
    "            self.scheduler.step()\n",
    "\n",
    "        # 학습 완료 후 최종 검증 손실 반환\n",
    "        return self.lowest_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f41c09-318a-4f2e-bdca-68d8a07e9938",
   "metadata": {
    "papermill": {
     "duration": 0.002798,
     "end_time": "2024-09-20T15:15:26.402940",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.400142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "698783c4-ac2a-4e66-82aa-637df06ce012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.409207Z",
     "iopub.status.busy": "2024-09-20T15:15:26.409018Z",
     "iopub.status.idle": "2024-09-20T15:15:26.410877Z",
     "shell.execute_reply": "2024-09-20T15:15:26.410616Z"
    },
    "papermill": {
     "duration": 0.005818,
     "end_time": "2024-09-20T15:15:26.411529",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.405711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습에 사용할 장비를 선택.\n",
    "# torch라이브러리에서 gpu를 인식할 경우, cuda로 설정.\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76cfe17e-fb14-42e4-84ae-b6773f0b78fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.417567Z",
     "iopub.status.busy": "2024-09-20T15:15:26.417423Z",
     "iopub.status.idle": "2024-09-20T15:15:26.419057Z",
     "shell.execute_reply": "2024-09-20T15:15:26.418823Z"
    },
    "papermill": {
     "duration": 0.005354,
     "end_time": "2024-09-20T15:15:26.419662",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.414308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "traindata_dir = \"./data/train\"\n",
    "traindata_info_file = \"./data/train.csv\"\n",
    "save_result_path = \"./train_result_code9_effv2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa914f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.425829Z",
     "iopub.status.busy": "2024-09-20T15:15:26.425623Z",
     "iopub.status.idle": "2024-09-20T15:15:26.434785Z",
     "shell.execute_reply": "2024-09-20T15:15:26.434522Z"
    },
    "papermill": {
     "duration": 0.012896,
     "end_time": "2024-09-20T15:15:26.435380",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.422484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "train_info = pd.read_csv(traindata_info_file)\n",
    "\n",
    "# 총 class의 수를 측정.\n",
    "num_classes = len(train_info['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db231faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.441484Z",
     "iopub.status.busy": "2024-09-20T15:15:26.441347Z",
     "iopub.status.idle": "2024-09-20T15:15:26.442969Z",
     "shell.execute_reply": "2024-09-20T15:15:26.442735Z"
    },
    "papermill": {
     "duration": 0.005314,
     "end_time": "2024-09-20T15:15:26.443530",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.438216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KFold 설정\n",
    "n_splits = 5  # 5-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfcf3912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.449619Z",
     "iopub.status.busy": "2024-09-20T15:15:26.449353Z",
     "iopub.status.idle": "2024-09-20T15:15:26.452711Z",
     "shell.execute_reply": "2024-09-20T15:15:26.452312Z"
    },
    "papermill": {
     "duration": 0.007138,
     "end_time": "2024-09-20T15:15:26.453421",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.446283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습에 사용할 Transform을 선언.\n",
    "transform_selector = TransformSelector(\n",
    "    transform_type = \"albumentations\"\n",
    ")\n",
    "train_transform = transform_selector.get_transform(is_train=True)\n",
    "val_transform = transform_selector.get_transform(is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b283513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.460376Z",
     "iopub.status.busy": "2024-09-20T15:15:26.459888Z",
     "iopub.status.idle": "2024-09-20T15:15:26.462216Z",
     "shell.execute_reply": "2024-09-20T15:15:26.461878Z"
    },
    "papermill": {
     "duration": 0.006594,
     "end_time": "2024-09-20T15:15:26.462916",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.456322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32715cca-5a4a-49d5-8fd9-f84da4581523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.469341Z",
     "iopub.status.busy": "2024-09-20T15:15:26.468971Z",
     "iopub.status.idle": "2024-09-20T15:15:26.471057Z",
     "shell.execute_reply": "2024-09-20T15:15:26.470700Z"
    },
    "papermill": {
     "duration": 0.006012,
     "end_time": "2024-09-20T15:15:26.471722",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.465710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습에 사용할 Loss를 선언.\n",
    "# loss_fn = Loss() #cross_entropy_loss\n",
    "loss_fn = FocalLoss(alpha=0.5, gamma=1) #focal_loss\n",
    "# loss_fn = LabelSmoothingLoss(classes=num_classes, smoothing=0.1) #Label_smoothing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10011e8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.477901Z",
     "iopub.status.busy": "2024-09-20T15:15:26.477619Z",
     "iopub.status.idle": "2024-09-20T15:15:26.479230Z",
     "shell.execute_reply": "2024-09-20T15:15:26.478993Z"
    },
    "papermill": {
     "duration": 0.005205,
     "end_time": "2024-09-20T15:15:26.479704",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.474499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 스케줄러 초기화\n",
    "# scheduler_step_size = 15  # 매 15step마다 학습률 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac64a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T15:15:26.485795Z",
     "iopub.status.busy": "2024-09-20T15:15:26.485706Z",
     "iopub.status.idle": "2024-09-21T13:13:07.029543Z",
     "shell.execute_reply": "2024-09-21T13:13:07.029192Z"
    },
    "papermill": {
     "duration": 79060.547922,
     "end_time": "2024-09-21T13:13:07.030422",
     "exception": false,
     "start_time": "2024-09-20T15:15:26.482500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KFold 교차 검증 수행\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_info, train_info['target'])):\n",
    "    print(f'Fold {fold + 1}/{n_splits}')\n",
    "\n",
    "    # train_df와 val_df를 train_idx와 val_idx로 분할\n",
    "    train_df = train_info.iloc[train_idx]\n",
    "    val_df = train_info.iloc[val_idx]\n",
    "\n",
    "    # 학습에 사용할 Model 선언 (매 Fold마다 모델을 초기화)\n",
    "    model_selector = ModelSelector(\n",
    "        model_type='timm', \n",
    "        num_classes=num_classes,\n",
    "        model_name='efficientnetv2_rw_t', \n",
    "        pretrained=True\n",
    "    )\n",
    "    model = model_selector.get_model().to(device)\n",
    "\n",
    "    # optimizer 선언\n",
    "    optimizer = RAdam(model.parameters(), lr=0.0001, betas=(0.9,0.999), eps=1e-8, weight_decay=1e-4, degenerated_to_sgd=False)\n",
    "    #optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "    # 학습에 사용할 Dataset 선언\n",
    "    train_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=train_df,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    val_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=val_df,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    # 학습에 사용할 DataLoader 선언\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    # 한 epoch당 step 수 계산\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    \n",
    "    scheduler_gamma = 0.7  # 학습률을 현재의 30%로 감소\n",
    "    epochs = 30\n",
    "    # StepLR\n",
    "    # 15 epoch마다 학습률을 감소시키는 스케줄러 선언\n",
    "    epochs_per_lr_decay = 20\n",
    "    scheduler_step_size = steps_per_epoch * epochs_per_lr_decay\n",
    "    \n",
    "    # 스케줄러 선언\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, \n",
    "        step_size=scheduler_step_size, \n",
    "        gamma=scheduler_gamma\n",
    "    )\n",
    "    \n",
    "    # #CosineAnnealingLR\n",
    "    # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=steps_per_epoch * epochs)\n",
    "\n",
    "    # Trainer 선언\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        device=device, \n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn, \n",
    "        epochs=epochs,  # 각 fold마다 동일한 epoch수로 학습\n",
    "        result_path=f\"{save_result_path}/fold_{fold + 1}\"  # 각 fold 결과 저장\n",
    "    )\n",
    "\n",
    "    # 모델 학습 및 결과 저장\n",
    "    fold_result = trainer.train()\n",
    "    fold_results.append(fold_result)\n",
    "\n",
    "# 각 Fold의 결과를 기반으로 평균 성능 계산\n",
    "average_performance = sum(fold_results) / len(fold_results)\n",
    "print(f'KFold 평균 성능: {average_performance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11087088-9b1f-4f7d-8eb5-72008cc88a50",
   "metadata": {
    "papermill": {
     "duration": 2.627969,
     "end_time": "2024-09-21T13:13:12.051967",
     "exception": false,
     "start_time": "2024-09-21T13:13:09.423998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64901ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:13:17.083672Z",
     "iopub.status.busy": "2024-09-21T13:13:17.083510Z",
     "iopub.status.idle": "2024-09-21T13:13:17.085983Z",
     "shell.execute_reply": "2024-09-21T13:13:17.085635Z"
    },
    "papermill": {
     "duration": 2.530779,
     "end_time": "2024-09-21T13:13:17.086631",
     "exception": false,
     "start_time": "2024-09-21T13:13:14.555852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 폴드 수 및 모델 저장 경로 설정\n",
    "n_folds = 5\n",
    "fold_model_paths = [f\"./train_result_code9_effv2/fold_{fold + 1}/best_model.pt\" for fold in range(n_folds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087a35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:13:22.115465Z",
     "iopub.status.busy": "2024-09-21T13:13:22.115273Z",
     "iopub.status.idle": "2024-09-21T13:13:22.117939Z",
     "shell.execute_reply": "2024-09-21T13:13:22.117608Z"
    },
    "papermill": {
     "duration": 2.508161,
     "end_time": "2024-09-21T13:13:22.118663",
     "exception": false,
     "start_time": "2024-09-21T13:13:19.610502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(fold_model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59e016d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:13:27.133627Z",
     "iopub.status.busy": "2024-09-21T13:13:27.133439Z",
     "iopub.status.idle": "2024-09-21T13:13:27.137258Z",
     "shell.execute_reply": "2024-09-21T13:13:27.136916Z"
    },
    "papermill": {
     "duration": 2.6382,
     "end_time": "2024-09-21T13:13:27.137912",
     "exception": false,
     "start_time": "2024-09-21T13:13:24.499712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 저장된 모델을 불러와서 앙상블을 수행하는 함수\n",
    "def ensemble_predict_folds(\n",
    "    fold_model_paths: list, \n",
    "    device: torch.device, \n",
    "    test_loader: DataLoader\n",
    "    ):\n",
    "    models = []\n",
    "    \n",
    "    # 각 폴드의 베스트 모델 불러오기\n",
    "    for fold_path in fold_model_paths:\n",
    "        # 모델 초기화 및 로드\n",
    "        model = ModelSelector(\n",
    "            model_type='timm', \n",
    "            num_classes=num_classes,\n",
    "            model_name='efficientnetv2_rw_t', \n",
    "            pretrained=False\n",
    "        ).get_model().to(device)\n",
    "        model.load_state_dict(torch.load(fold_path, map_location=device))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            # 이미지를 GPU 또는 CPU로 이동\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # 폴드별 예측 수행\n",
    "            fold_preds = []\n",
    "            for model in models:\n",
    "                logits = model(images)\n",
    "                logits = F.softmax(logits, dim=1)  # 확률값으로 변환\n",
    "                fold_preds.append(logits)\n",
    "            \n",
    "            # 폴드별 예측 결과 평균\n",
    "            avg_preds = torch.mean(torch.stack(fold_preds), dim=0)\n",
    "            final_preds = avg_preds.argmax(dim=1)\n",
    "            \n",
    "            # 예측 결과 저장\n",
    "            predictions.extend(final_preds.cpu().detach().numpy())\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b407c24c-785d-4ffc-b17b-84ae7dc4ecae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:13:32.178389Z",
     "iopub.status.busy": "2024-09-21T13:13:32.178203Z",
     "iopub.status.idle": "2024-09-21T13:13:32.180684Z",
     "shell.execute_reply": "2024-09-21T13:13:32.180261Z"
    },
    "papermill": {
     "duration": 2.506745,
     "end_time": "2024-09-21T13:13:32.181385",
     "exception": false,
     "start_time": "2024-09-21T13:13:29.674640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추론 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "testdata_dir = \"./data/test\"\n",
    "testdata_info_file = \"./data/test.csv\"\n",
    "save_result_path = \"./train_result_code9_effv2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbb89c12-3b5d-4647-a8c2-83650dce6281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:13:37.055772Z",
     "iopub.status.busy": "2024-09-21T13:13:37.055589Z",
     "iopub.status.idle": "2024-09-21T13:13:37.060111Z",
     "shell.execute_reply": "2024-09-21T13:13:37.059772Z"
    },
    "papermill": {
     "duration": 2.354958,
     "end_time": "2024-09-21T13:13:37.060798",
     "exception": false,
     "start_time": "2024-09-21T13:13:34.705840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추론 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "test_info = pd.read_csv(testdata_info_file)\n",
    "\n",
    "# 총 class 수.\n",
    "num_classes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecec8773-6045-401e-b307-0a9758374c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:13:42.223291Z",
     "iopub.status.busy": "2024-09-21T13:13:42.223105Z",
     "iopub.status.idle": "2024-09-21T13:13:42.226506Z",
     "shell.execute_reply": "2024-09-21T13:13:42.226159Z"
    },
    "papermill": {
     "duration": 2.530057,
     "end_time": "2024-09-21T13:13:42.227192",
     "exception": false,
     "start_time": "2024-09-21T13:13:39.697135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추론에 사용할 Transform을 선언.\n",
    "transform_selector = TransformSelector(\n",
    "    transform_type = \"albumentations\"\n",
    ")\n",
    "test_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "# 추론에 사용할 Dataset을 선언.\n",
    "test_dataset = CustomDataset(\n",
    "    root_dir=testdata_dir,\n",
    "    info_df=test_info,\n",
    "    transform=test_transform,\n",
    "    is_inference=True\n",
    ")\n",
    "\n",
    "# 추론에 사용할 DataLoader를 선언.\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb15fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:13:47.253629Z",
     "iopub.status.busy": "2024-09-21T13:13:47.253385Z",
     "iopub.status.idle": "2024-09-21T13:14:55.732302Z",
     "shell.execute_reply": "2024-09-21T13:14:55.731809Z"
    },
    "papermill": {
     "duration": 70.986961,
     "end_time": "2024-09-21T13:14:55.733195",
     "exception": false,
     "start_time": "2024-09-21T13:13:44.746234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 폴드별 저장된 모델을 사용한 앙상블 추론 실행\n",
    "predictions = ensemble_predict_folds(\n",
    "    fold_model_paths=fold_model_paths, \n",
    "    device=device, \n",
    "    test_loader=test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96c889-2423-42b2-8c3c-4b1d364ece71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:00.872525Z",
     "iopub.status.busy": "2024-09-21T13:15:00.872339Z",
     "iopub.status.idle": "2024-09-21T13:15:00.886810Z",
     "shell.execute_reply": "2024-09-21T13:15:00.886547Z"
    },
    "papermill": {
     "duration": 2.524127,
     "end_time": "2024-09-21T13:15:00.887769",
     "exception": false,
     "start_time": "2024-09-21T13:14:58.363642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모든 클래스에 대한 예측 결과를 하나의 문자열로 합침\n",
    "test_info['target'] = predictions\n",
    "test_info = test_info.reset_index().rename(columns={\"index\": \"ID\"})\n",
    "test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4efd2f6-d74a-491b-a7b1-fd7cf96f45a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:05.917655Z",
     "iopub.status.busy": "2024-09-21T13:15:05.917493Z",
     "iopub.status.idle": "2024-09-21T13:15:05.924294Z",
     "shell.execute_reply": "2024-09-21T13:15:05.924052Z"
    },
    "papermill": {
     "duration": 2.50211,
     "end_time": "2024-09-21T13:15:05.924842",
     "exception": false,
     "start_time": "2024-09-21T13:15:03.422732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 예측 결과를 CSV 파일로 저장\n",
    "test_info.to_csv(\"output_code9_effv2.csv\", index=False)\n",
    "print(f\"추론 결과가 output_code9_effv2.csv 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac79e3df-e5c3-4a49-b37e-0dea1300c317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:10.815977Z",
     "iopub.status.busy": "2024-09-21T13:15:10.815792Z",
     "iopub.status.idle": "2024-09-21T13:15:10.818903Z",
     "shell.execute_reply": "2024-09-21T13:15:10.818549Z"
    },
    "papermill": {
     "duration": 2.36276,
     "end_time": "2024-09-21T13:15:10.819495",
     "exception": false,
     "start_time": "2024-09-21T13:15:08.456735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def visualize_gradcam(\n",
    "#         model: torch.nn.Module,\n",
    "#         device: torch.device,\n",
    "#         dataloader: DataLoader,\n",
    "#         target_layer: str,\n",
    "#         image_index: int\n",
    "#     ):\n",
    "\n",
    "#     # Grad-CAM 추출기를 초기화합니다.\n",
    "#     cam_extractor = GradCAM(model, target_layer)\n",
    "    \n",
    "#     model.eval()  # 모델을 평가 모드로 설정합니다.\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # 시각화를 위한 Figure를 생성합니다.\n",
    "    \n",
    "#     # 데이터 로더에서 배치를 반복합니다.\n",
    "#     current_index = 0\n",
    "#     for inputs in dataloader:\n",
    "#         inputs = inputs.to(device)  # 입력 이미지를 장치로 이동합니다.\n",
    "        \n",
    "#         outputs = model(inputs)  # 모델을 통해 예측을 수행합니다.\n",
    "#         _, preds = torch.max(outputs, 1)  # 예측된 클래스 인덱스를 가져옵니다.\n",
    "        \n",
    "#         # 배치 내의 각 이미지에 대해 처리합니다.\n",
    "#         for j in range(inputs.size()[0]):\n",
    "#             if current_index == image_index:\n",
    "#                 # CAM을 가져옵니다.\n",
    "#                 cam = cam_extractor(preds[j].item(), outputs[j].unsqueeze(0))[0]\n",
    "#                 # CAM을 1채널로 변환합니다.\n",
    "#                 cam = cam.mean(dim=0).cpu().numpy()\n",
    "                \n",
    "#                 # CAM을 원본 이미지 크기로 리사이즈합니다.\n",
    "#                 cam = cv2.resize(cam, (inputs[j].shape[2], inputs[j].shape[1]))\n",
    "                \n",
    "#                 # CAM을 정규화합니다.\n",
    "#                 cam = (cam - cam.min()) / (cam.max() - cam.min())  # 정규화\n",
    "#                 ㅈ\n",
    "#                 # CAM을 0-255 범위로 변환합니다.\n",
    "#                 cam = np.uint8(255 * cam)\n",
    "#                 # 컬러맵을 적용하여 RGB 이미지로 변환합니다.\n",
    "#                 cam = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "#                 cam = cv2.cvtColor(cam, cv2.COLOR_BGR2RGB)  # BGR에서 RGB로 변환\n",
    "                \n",
    "#                 # 입력 이미지가 1채널 또는 3채널인지 확인하고 처리합니다.\n",
    "#                 input_image = inputs[j].cpu().numpy().transpose((1, 2, 0))\n",
    "#                 if input_image.shape[2] == 1:  # 1채널 이미지인 경우\n",
    "#                     input_image = np.squeeze(input_image, axis=2)  # (H, W, 1) -> (H, W)\n",
    "#                     input_image = np.stack([input_image] * 3, axis=-1)  # (H, W) -> (H, W, 3)로 변환하여 RGB처럼 만듭니다.\n",
    "#                 else:  # 3채널 이미지인 경우\n",
    "#                     input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "#                     input_image = (input_image * 255).astype(np.uint8)  # 정규화된 이미지를 8비트 이미지로 변환합니다.\n",
    "                \n",
    "#                 # 오리지널 이미지\n",
    "#                 axes[0].imshow(input_image)\n",
    "#                 axes[0].set_title(\"Original Image\")\n",
    "#                 axes[0].axis('off')\n",
    "                \n",
    "#                 # Grad-CAM 이미지\n",
    "#                 axes[1].imshow(cam)\n",
    "#                 axes[1].set_title(\"Grad-CAM Image\")\n",
    "#                 axes[1].axis('off')\n",
    "                \n",
    "#                 # 오버레이된 이미지 생성\n",
    "#                 overlay = cv2.addWeighted(input_image, 0.5, cam, 0.5, 0)\n",
    "#                 axes[2].imshow(overlay)\n",
    "#                 axes[2].set_title(\"Overlay Image\")\n",
    "#                 axes[2].axis('off')\n",
    "                \n",
    "#                 plt.show()  # 시각화를 표시합니다.\n",
    "#                 return\n",
    "#             current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91cd0879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:15.945901Z",
     "iopub.status.busy": "2024-09-21T13:15:15.945712Z",
     "iopub.status.idle": "2024-09-21T13:15:15.948188Z",
     "shell.execute_reply": "2024-09-21T13:15:15.947852Z"
    },
    "papermill": {
     "duration": 2.515503,
     "end_time": "2024-09-21T13:15:15.948761",
     "exception": false,
     "start_time": "2024-09-21T13:15:13.433258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ace35397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:20.978295Z",
     "iopub.status.busy": "2024-09-21T13:15:20.978106Z",
     "iopub.status.idle": "2024-09-21T13:15:20.980470Z",
     "shell.execute_reply": "2024-09-21T13:15:20.980024Z"
    },
    "papermill": {
     "duration": 2.516644,
     "end_time": "2024-09-21T13:15:20.981054",
     "exception": false,
     "start_time": "2024-09-21T13:15:18.464410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target_layer = 'layer4.1.act2'\n",
    "\n",
    "# # Grad-CAM 시각화 실행 (예: 인덱스 3의 이미지를 시각화)\n",
    "\n",
    "# image_index = 3\n",
    "\n",
    "# visualize_gradcam(model.model, device, test_loader, target_layer=target_layer, image_index=image_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 79200.838937,
   "end_time": "2024-09-21T13:15:24.281505",
   "environment_variables": {},
   "exception": null,
   "input_path": "code8_nf.ipynb",
   "output_path": "code8_nf_result.ipynb",
   "parameters": {},
   "start_time": "2024-09-20T15:15:23.442568",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
