{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af8a2c0-45fe-4d13-bebd-0dca87a7b71f",
   "metadata": {
    "papermill": {
     "duration": 0.003689,
     "end_time": "2024-09-23T08:45:12.717721",
     "exception": false,
     "start_time": "2024-09-23T08:45:12.714032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a4c611c8-2226-433c-bf5f-343cc0b094af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:12.730333Z",
     "iopub.status.busy": "2024-09-23T08:45:12.730152Z",
     "iopub.status.idle": "2024-09-23T08:45:14.954817Z",
     "shell.execute_reply": "2024-09-23T08:45:14.954330Z"
    },
    "papermill": {
     "duration": 2.229568,
     "end_time": "2024-09-23T08:45:14.955924",
     "exception": false,
     "start_time": "2024-09-23T08:45:12.726356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, Callable, Union\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d69e6a-a719-4a97-92ca-6354c873313f",
   "metadata": {
    "papermill": {
     "duration": 0.003114,
     "end_time": "2024-09-23T08:45:14.986159",
     "exception": false,
     "start_time": "2024-09-23T08:45:14.983045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "56f97229-e29f-479d-abab-0db8219d1803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:14.993342Z",
     "iopub.status.busy": "2024-09-23T08:45:14.993200Z",
     "iopub.status.idle": "2024-09-23T08:45:14.997411Z",
     "shell.execute_reply": "2024-09-23T08:45:14.997110Z"
    },
    "papermill": {
     "duration": 0.008743,
     "end_time": "2024-09-23T08:45:14.998138",
     "exception": false,
     "start_time": "2024-09-23T08:45:14.989395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        root_dir: str, \n",
    "        info_df: pd.DataFrame, \n",
    "        transform: Callable,\n",
    "        is_inference: bool = False\n",
    "    ):\n",
    "        # 데이터셋 기본 경로, 이미지 변환 방법, 이미지 경로 및 레이블 초기화\n",
    "        self.root_dir = root_dir  # 이미지 파일 root\n",
    "        self.transform = transform  # 이미지 변환 처리\n",
    "        self.is_inference = is_inference # 추론 확인\n",
    "        self.image_paths = info_df['image_path'].tolist()  # 이미지 파일 경로 목록\n",
    "        \n",
    "        if not self.is_inference:\n",
    "            self.targets = info_df['target'].tolist()  # 각 이미지에 대한 레이블 목록\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # 데이터셋의 총 이미지 수를 반환\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[Tuple[torch.Tensor, int], torch.Tensor]:\n",
    "        # 주어진 인덱스에 해당하는 이미지를 로드하고 변환을 적용한 후, 이미지와 레이블을 반환\n",
    "        img_path = os.path.join(self.root_dir, self.image_paths[index])  # 이미지 경로 조합  \n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)  # 이미지를 BGR 컬러 포맷의 numpy array로 Read\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR 포맷을 RGB 포맷으로 변환\n",
    "        image = self.transform(image)  # 설정된 이미지 변환을 적용\n",
    "\n",
    "        if self.is_inference:\n",
    "            return image\n",
    "        else:\n",
    "            target = self.targets[index]  # 해당 이미지의 레이블\n",
    "            return image, target  # 변환된 이미지와 레이블을 튜플 형태로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07d2d0-9585-45ce-8ece-4f69b98f6dd4",
   "metadata": {
    "papermill": {
     "duration": 0.003027,
     "end_time": "2024-09-23T08:45:15.004199",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.001172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transform Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b5dd6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsharpMask(A.ImageOnlyTransform):\n",
    "    def __init__(self, kernel_size, sigma, amount, threshold, always_apply=False, p=1.0):\n",
    "        super(UnsharpMask, self).__init__(always_apply, p)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.amount = amount\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        return self.unsharp_mask(image)\n",
    "\n",
    "    def unsharp_mask(self, image):\n",
    "        blurred = cv2.GaussianBlur(image, (self.kernel_size, self.kernel_size), self.sigma)\n",
    "        sharpened = cv2.addWeighted(image, 1.0 + self.amount, blurred, -self.amount, 0)\n",
    "        if self.threshold > 0:\n",
    "            low_contrast_mask = np.absolute(image - blurred) < self.threshold\n",
    "            np.copyto(sharpened, image, where=low_contrast_mask)\n",
    "        return sharpened\n",
    "\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, is_train: bool = True):\n",
    "        # 공통 변환 설정: 이미지 리사이즈, 그레이스케일 변환, 언샤프 마스크, 정규화, 텐서 변환\n",
    "        common_transforms = [\n",
    "            A.Resize(224, 224),  # 이미지를 224x224 크기로 리사이즈\n",
    "            UnsharpMask(kernel_size=7, sigma=1.5, amount=1.5, threshold=0, p=1.0),  # UnsharpMask 적용\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.2, -0.2), contrast_limit=0, p=1.0), # 20% 어둡게\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 정규화            \n",
    "            ToTensorV2(),  # albumentations에서 제공하는 PyTorch 텐서 변환\n",
    "        ]\n",
    "\n",
    "        if is_train:\n",
    "            # 훈련용 변환: 랜덤 크롭, 랜덤 수평 뒤집기, 랜덤 회전 추가\n",
    "            self.transform = A.Compose(\n",
    "                [\n",
    "                    A.HorizontalFlip(p=0.5),  # 50% 확률로 이미지를 수평 뒤집기\n",
    "                    A.Rotate(limit=30),  # 최대 30도 회전\n",
    "                    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.5), # 50% 확률로 블럭 추가\n",
    "                    A.GridDistortion(num_steps=1, distort_limit=(-0.03, 0.05), interpolation=2, border_mode=0, value=(255, 255, 255), p=1) # 격자모양으로 왜곡을 적용\n",
    "                ] + common_transforms\n",
    "            )\n",
    "        else:\n",
    "            # 검증/테스트용 변환: 공통 변환만 적용\n",
    "            self.transform = A.Compose(common_transforms)\n",
    "\n",
    "    def __call__(self, image) -> torch.Tensor:\n",
    "        # 이미지가 NumPy 배열인지 확인\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            raise TypeError(\"Image should be a NumPy array (OpenCV format).\")\n",
    "\n",
    "        # 이미지에 변환 적용\n",
    "        transformed = self.transform(image=image)  # 이미지에 설정된 변환을 적용\n",
    "\n",
    "        return transformed['image']  # 변환된 이미지의 텐서를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e82f3416-86f2-430f-9260-d23904e757e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.036233Z",
     "iopub.status.busy": "2024-09-23T08:45:15.036086Z",
     "iopub.status.idle": "2024-09-23T08:45:15.038561Z",
     "shell.execute_reply": "2024-09-23T08:45:15.038347Z"
    },
    "papermill": {
     "duration": 0.006885,
     "end_time": "2024-09-23T08:45:15.039291",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.032406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformSelector:\n",
    "    \"\"\"\n",
    "    이미지 변환 라이브러리를 선택하기 위한 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, transform_type: str):\n",
    "        # 지원하는 변환 라이브러리인지 확인\n",
    "        if transform_type == \"albumentations\":\n",
    "            self.transform_type = transform_type        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown transformation library specified.\")\n",
    "\n",
    "    def get_transform(self, is_train: bool):        \n",
    "        transform = AlbumentationsTransform(is_train=is_train)\n",
    "                \n",
    "        return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938bcb2-9257-49cb-8d05-dd4a7bb25665",
   "metadata": {
    "papermill": {
     "duration": 0.003035,
     "end_time": "2024-09-23T08:45:15.045328",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.042293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f28c8e4f-a914-4b12-982e-d4a58863c717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.072685Z",
     "iopub.status.busy": "2024-09-23T08:45:15.072531Z",
     "iopub.status.idle": "2024-09-23T08:45:15.075057Z",
     "shell.execute_reply": "2024-09-23T08:45:15.074642Z"
    },
    "papermill": {
     "duration": 0.007109,
     "end_time": "2024-09-23T08:45:15.075859",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.068750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Timm 라이브러리를 사용하여 다양한 사전 훈련된 모델을 제공하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str, \n",
    "        num_classes: int, \n",
    "        pretrained: bool\n",
    "    ):\n",
    "        super(TimmModel, self).__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f2da081-9010-431d-a049-835d7bbea4a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.082475Z",
     "iopub.status.busy": "2024-09-23T08:45:15.082343Z",
     "iopub.status.idle": "2024-09-23T08:45:15.085154Z",
     "shell.execute_reply": "2024-09-23T08:45:15.084751Z"
    },
    "papermill": {
     "duration": 0.007213,
     "end_time": "2024-09-23T08:45:15.086070",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.078857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelSelector:\n",
    "    \"\"\"\n",
    "    사용할 모델 유형을 선택하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_type: str, \n",
    "        num_classes: int, \n",
    "        **kwargs\n",
    "    ):        \n",
    "        # 모델 유형에 따라 적절한 모델 객체를 생성        \n",
    "        if model_type == 'timm':\n",
    "            self.model = TimmModel(num_classes=num_classes, **kwargs)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown model type specified.\")\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "\n",
    "        # 생성된 모델 객체 반환\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2977c7b-bc39-48f7-8155-ef6b6a03d6f8",
   "metadata": {
    "papermill": {
     "duration": 0.003157,
     "end_time": "2024-09-23T08:45:15.092205",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.089048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c51e6c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.138791Z",
     "iopub.status.busy": "2024-09-23T08:45:15.138660Z",
     "iopub.status.idle": "2024-09-23T08:45:15.141338Z",
     "shell.execute_reply": "2024-09-23T08:45:15.141055Z"
    },
    "papermill": {
     "duration": 0.006714,
     "end_time": "2024-09-23T08:45:15.141981",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.135267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none') # Cross Entropy Loss 계산\n",
    "        pt = torch.exp(-ce_loss) # 예측 확률 계산\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss # Focal Loss 계산\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e3d21-5ab8-41b0-aa5c-e62ace8dc6a6",
   "metadata": {
    "papermill": {
     "duration": 0.003061,
     "end_time": "2024-09-23T08:45:15.159091",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.156030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6a90c673-6672-4066-a9ec-9975d7842be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.166158Z",
     "iopub.status.busy": "2024-09-23T08:45:15.165972Z",
     "iopub.status.idle": "2024-09-23T08:45:15.174090Z",
     "shell.execute_reply": "2024-09-23T08:45:15.173530Z"
    },
    "papermill": {
     "duration": 0.012489,
     "end_time": "2024-09-23T08:45:15.174721",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.162232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        device: torch.device, \n",
    "        train_loader: DataLoader, \n",
    "        val_loader: DataLoader, \n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler: optim.lr_scheduler,\n",
    "        loss_fn: torch.nn.modules.loss._Loss, \n",
    "        epochs: int,\n",
    "        result_path: str\n",
    "    ):\n",
    "        # 클래스 초기화: 모델, 디바이스, 데이터 로더 등 설정\n",
    "        self.model = model  # 훈련할 모델\n",
    "        self.device = device  # 연산을 수행할 디바이스 (CPU or GPU)\n",
    "        self.train_loader = train_loader  # 훈련 데이터 로더\n",
    "        self.val_loader = val_loader  # 검증 데이터 로더\n",
    "        self.optimizer = optimizer  # 최적화 알고리즘\n",
    "        self.scheduler = scheduler  # 학습률 스케줄러\n",
    "        self.loss_fn = loss_fn  # 손실 함수\n",
    "        self.epochs = epochs  # 총 훈련 에폭 수\n",
    "        self.result_path = result_path  # 모델 저장 경로\n",
    "        self.best_models = []  # 가장 좋은 상위 3개 모델의 정보를 저장할 리스트\n",
    "        self.lowest_loss = float('inf')  # 가장 낮은 Loss를 저장할 변수\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        # 모델 저장 경로 설정\n",
    "        os.makedirs(self.result_path, exist_ok=True)\n",
    "\n",
    "        # 현재 에폭 모델 저장\n",
    "        current_model_path = os.path.join(self.result_path, f'model_epoch_{epoch}_loss_{loss:.4f}.pt')\n",
    "        torch.save(self.model.state_dict(), current_model_path)\n",
    "\n",
    "        # 최상위 3개 모델 관리\n",
    "        self.best_models.append((loss, epoch, current_model_path))\n",
    "        self.best_models.sort()\n",
    "        if len(self.best_models) > 3:\n",
    "            _, _, path_to_remove = self.best_models.pop(-1)  # 가장 높은 손실 모델 삭제\n",
    "            if os.path.exists(path_to_remove):\n",
    "                os.remove(path_to_remove)\n",
    "\n",
    "        # 가장 낮은 손실의 모델 저장\n",
    "        if loss < self.lowest_loss:\n",
    "            self.lowest_loss = loss\n",
    "            best_model_path = os.path.join(self.result_path, 'best_model.pt')\n",
    "            torch.save(self.model.state_dict(), best_model_path)\n",
    "            print(f\"Save {epoch}epoch result. Loss = {loss:.4f}\")\n",
    "\n",
    "    def train_epoch(self) -> float:\n",
    "        # 한 에폭 동안의 훈련을 진행\n",
    "        self.model.train()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "                \n",
    "        progress_bar = tqdm(self.train_loader, desc=\"Training\", leave=False)\n",
    "\n",
    "        for images, targets in progress_bar:\n",
    "            images, targets = images.to(self.device), targets.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)  # 예측된 클래스\n",
    "            correct_predictions += (preds == targets).sum().item()  # 맞춘 예측 개수\n",
    "            total_samples += targets.size(0)  # 전체 샘플 수\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "            \n",
    "        accuracy = correct_predictions / total_samples * 100  # 정확도 계산\n",
    "        print(f\"Train Accuracy: {accuracy:.2f}%\")            \n",
    "\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    def validate(self) -> float:\n",
    "        # 모델의 검증을 진행\n",
    "        self.model.eval()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        progress_bar = tqdm(self.val_loader, desc=\"Validating\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in progress_bar:\n",
    "                images, targets = images.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # 정확도 계산\n",
    "                _, preds = torch.max(outputs, 1)  # 예측된 클래스\n",
    "                correct_predictions += (preds == targets).sum().item()  # 맞춘 예측 개수\n",
    "                total_samples += targets.size(0)  # 전체 샘플 수                \n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        accuracy = correct_predictions / total_samples * 100  # 정확도 계산\n",
    "        print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        return total_loss / len(self.val_loader)\n",
    "\n",
    "    def train(self) -> float:\n",
    "        # 전체 훈련 과정을 관리\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "\n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss = self.validate()\n",
    "\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Learning Rate: {current_lr:.6f}\\n\")\n",
    "\n",
    "            self.save_model(epoch, val_loss)\n",
    "            self.scheduler.step()\n",
    "\n",
    "        # 학습 완료 후 최종 검증 손실 반환\n",
    "        return self.lowest_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f41c09-318a-4f2e-bdca-68d8a07e9938",
   "metadata": {
    "papermill": {
     "duration": 0.003328,
     "end_time": "2024-09-23T08:45:15.181269",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.177941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "698783c4-ac2a-4e66-82aa-637df06ce012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.188509Z",
     "iopub.status.busy": "2024-09-23T08:45:15.188284Z",
     "iopub.status.idle": "2024-09-23T08:45:15.190774Z",
     "shell.execute_reply": "2024-09-23T08:45:15.190474Z"
    },
    "papermill": {
     "duration": 0.007007,
     "end_time": "2024-09-23T08:45:15.191369",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.184362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습에 사용할 장비를 선택.\n",
    "# torch라이브러리에서 gpu를 인식할 경우, cuda로 설정.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "76cfe17e-fb14-42e4-84ae-b6773f0b78fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.197874Z",
     "iopub.status.busy": "2024-09-23T08:45:15.197780Z",
     "iopub.status.idle": "2024-09-23T08:45:15.199562Z",
     "shell.execute_reply": "2024-09-23T08:45:15.199289Z"
    },
    "papermill": {
     "duration": 0.005722,
     "end_time": "2024-09-23T08:45:15.200103",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.194381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "traindata_dir = \"./data/train\"\n",
    "traindata_info_file = \"./data/train.csv\"\n",
    "save_result_path = \"./train_result_v4_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aa914f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.206633Z",
     "iopub.status.busy": "2024-09-23T08:45:15.206497Z",
     "iopub.status.idle": "2024-09-23T08:45:15.215944Z",
     "shell.execute_reply": "2024-09-23T08:45:15.215600Z"
    },
    "papermill": {
     "duration": 0.01377,
     "end_time": "2024-09-23T08:45:15.216837",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.203067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "train_info = pd.read_csv(traindata_info_file)\n",
    "\n",
    "# 총 class의 수를 측정.\n",
    "num_classes = len(train_info['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "db231faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.223959Z",
     "iopub.status.busy": "2024-09-23T08:45:15.223783Z",
     "iopub.status.idle": "2024-09-23T08:45:15.225949Z",
     "shell.execute_reply": "2024-09-23T08:45:15.225557Z"
    },
    "papermill": {
     "duration": 0.006595,
     "end_time": "2024-09-23T08:45:15.226703",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.220108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KFold 설정\n",
    "n_splits = 5  # 5-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "32715cca-5a4a-49d5-8fd9-f84da4581523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T08:45:15.263481Z",
     "iopub.status.busy": "2024-09-23T08:45:15.263359Z",
     "iopub.status.idle": "2024-09-23T08:45:15.265396Z",
     "shell.execute_reply": "2024-09-23T08:45:15.265090Z"
    },
    "papermill": {
     "duration": 0.007964,
     "end_time": "2024-09-23T08:45:15.266034",
     "exception": false,
     "start_time": "2024-09-23T08:45:15.258070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습에 사용할 Loss를 선언.\n",
    "loss_fn = FocalLoss(alpha=0.5, gamma=2) # focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa9ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold 교차 검증 수행\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_info, train_info['target'])):\n",
    "    print(f'Fold {fold + 1}/{n_splits}')\n",
    "    \n",
    "    # 학습에 사용할 Transform을 선언\n",
    "    transform_selector = TransformSelector(transform_type = \"albumentations\")\n",
    "    \n",
    "    train_transform = transform_selector.get_transform(is_train=True)\n",
    "    val_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "    # train_df와 val_df를 train_idx와 val_idx로 분할\n",
    "    train_df = train_info.iloc[train_idx]\n",
    "    val_df = train_info.iloc[val_idx]\n",
    "    \n",
    "    # 학습에 사용할 Dataset 선언\n",
    "    train_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=train_df,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    val_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=val_df,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    # 학습에 사용할 DataLoader 선언\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # 학습에 사용할 Model 선언 (매 Fold마다 모델을 초기화)\n",
    "    model_selector = ModelSelector(\n",
    "        model_type='timm', \n",
    "        num_classes=num_classes,\n",
    "        model_name='caformer_b36.sail_in22k', \n",
    "        pretrained=True\n",
    "    )\n",
    "    model = model_selector.get_model().to(device)\n",
    "\n",
    "    # optimizer 선언\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.00005, weight_decay=1e-5)\n",
    "\n",
    "    # 스케줄러 선언\n",
    "    steps_per_epoch = len(train_loader)  # 1epoch step\n",
    "    scheduler_gamma = 0.5  # 학습률을 현재의 50%로 감소\n",
    "    epochs_per_lr_decay = 10  # 10 epoch마다 학습률을 감소\n",
    "    scheduler_step_size = steps_per_epoch * epochs_per_lr_decay\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, \n",
    "        step_size=scheduler_step_size, \n",
    "        gamma=scheduler_gamma\n",
    "    )\n",
    "\n",
    "    # Trainer 선언\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        device=device, \n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn, \n",
    "        epochs=40,  # 각 fold마다 동일한 epoch수로 학습\n",
    "        result_path=f\"{save_result_path}/fold_{fold + 1}\"  # 각 fold 결과 저장\n",
    "    )\n",
    "\n",
    "    # 모델 학습 및 결과 저장\n",
    "    fold_result = trainer.train()\n",
    "    fold_results.append(fold_result)\n",
    "\n",
    "# 각 Fold의 결과를 기반으로 평균 성능 계산\n",
    "average_performance = sum(fold_results) / len(fold_results)\n",
    "print(f'KFold 평균 성능: {average_performance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1cb553f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴드 수 및 모델 저장 경로 설정\n",
    "n_folds = 5\n",
    "fold_model_paths = [f\"./train_result/fold_{fold + 1}/best_model.pt\" for fold in range(n_folds) if fold<2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11087088-9b1f-4f7d-8eb5-72008cc88a50",
   "metadata": {
    "papermill": {
     "duration": 3.241872,
     "end_time": "2024-09-24T03:29:45.651368",
     "exception": false,
     "start_time": "2024-09-24T03:29:42.409496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59e016d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:04.844866Z",
     "iopub.status.busy": "2024-09-24T03:30:04.844442Z",
     "iopub.status.idle": "2024-09-24T03:30:04.847989Z",
     "shell.execute_reply": "2024-09-24T03:30:04.847751Z"
    },
    "papermill": {
     "duration": 3.306368,
     "end_time": "2024-09-24T03:30:04.848569",
     "exception": false,
     "start_time": "2024-09-24T03:30:01.542201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 저장된 모델을 불러와서 앙상블을 수행하는 함수\n",
    "def ensemble_predict_folds(\n",
    "    fold_model_paths: list, \n",
    "    device: torch.device, \n",
    "    test_loader: DataLoader\n",
    "    ):\n",
    "    models = []\n",
    "    \n",
    "    # 각 폴드의 베스트 모델 불러오기\n",
    "    for fold_path in fold_model_paths:\n",
    "        # 모델 초기화 및 로드\n",
    "        model = ModelSelector(\n",
    "            model_type='timm', \n",
    "            num_classes=num_classes,\n",
    "            model_name='caformer_b36.sail_in22k', \n",
    "            pretrained=False\n",
    "        ).get_model().to(device)\n",
    "        model.load_state_dict(torch.load(fold_path, map_location=device))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            # 이미지를 GPU 또는 CPU로 이동\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # 폴드별 예측 수행\n",
    "            fold_preds = []\n",
    "            for model in models:\n",
    "                logits = model(images)\n",
    "                logits = F.softmax(logits, dim=1)  # 확률값으로 변환\n",
    "                fold_preds.append(logits)\n",
    "            \n",
    "            # 폴드별 예측 결과 평균\n",
    "            avg_preds = torch.mean(torch.stack(fold_preds), dim=0)\n",
    "            final_preds = avg_preds.argmax(dim=1)\n",
    "            \n",
    "            # 예측 결과 저장\n",
    "            predictions.extend(final_preds.cpu().detach().numpy())\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b407c24c-785d-4ffc-b17b-84ae7dc4ecae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:11.244864Z",
     "iopub.status.busy": "2024-09-24T03:30:11.244632Z",
     "iopub.status.idle": "2024-09-24T03:30:11.246732Z",
     "shell.execute_reply": "2024-09-24T03:30:11.246474Z"
    },
    "papermill": {
     "duration": 3.300085,
     "end_time": "2024-09-24T03:30:11.247343",
     "exception": false,
     "start_time": "2024-09-24T03:30:07.947258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추론 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "testdata_dir = \"./data/test\"\n",
    "testdata_info_file = \"./data/test.csv\"\n",
    "save_result_path = \"./train_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbb89c12-3b5d-4647-a8c2-83650dce6281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:17.675559Z",
     "iopub.status.busy": "2024-09-24T03:30:17.675200Z",
     "iopub.status.idle": "2024-09-24T03:30:17.681593Z",
     "shell.execute_reply": "2024-09-24T03:30:17.681160Z"
    },
    "papermill": {
     "duration": 3.300408,
     "end_time": "2024-09-24T03:30:17.682597",
     "exception": false,
     "start_time": "2024-09-24T03:30:14.382189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추론 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "test_info = pd.read_csv(testdata_info_file)\n",
    "\n",
    "# 총 class 수.\n",
    "num_classes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ecec8773-6045-401e-b307-0a9758374c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:24.370899Z",
     "iopub.status.busy": "2024-09-24T03:30:24.370677Z",
     "iopub.status.idle": "2024-09-24T03:30:24.374845Z",
     "shell.execute_reply": "2024-09-24T03:30:24.374341Z"
    },
    "papermill": {
     "duration": 3.279078,
     "end_time": "2024-09-24T03:30:24.375845",
     "exception": false,
     "start_time": "2024-09-24T03:30:21.096767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추론에 사용할 Transform을 선언.\n",
    "transform_selector = TransformSelector(\n",
    "    transform_type = \"albumentations\"\n",
    ")\n",
    "test_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "# 추론에 사용할 Dataset을 선언.\n",
    "test_dataset = CustomDataset(\n",
    "    root_dir=testdata_dir,\n",
    "    info_df=test_info,\n",
    "    transform=test_transform,\n",
    "    is_inference=True\n",
    ")\n",
    "\n",
    "# 추론에 사용할 DataLoader를 선언.\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb15fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:30:30.698339Z",
     "iopub.status.busy": "2024-09-24T03:30:30.697897Z",
     "iopub.status.idle": "2024-09-24T03:31:32.721371Z",
     "shell.execute_reply": "2024-09-24T03:31:32.720776Z"
    },
    "papermill": {
     "duration": 65.245117,
     "end_time": "2024-09-24T03:31:32.722092",
     "exception": false,
     "start_time": "2024-09-24T03:30:27.476975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 폴드별 저장된 모델을 사용한 앙상블 추론 실행\n",
    "predictions = ensemble_predict_folds(\n",
    "    fold_model_paths=fold_model_paths, \n",
    "    device=device, \n",
    "    test_loader=test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96c889-2423-42b2-8c3c-4b1d364ece71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:31:38.832057Z",
     "iopub.status.busy": "2024-09-24T03:31:38.831586Z",
     "iopub.status.idle": "2024-09-24T03:31:38.846518Z",
     "shell.execute_reply": "2024-09-24T03:31:38.846294Z"
    },
    "papermill": {
     "duration": 3.057988,
     "end_time": "2024-09-24T03:31:38.847111",
     "exception": false,
     "start_time": "2024-09-24T03:31:35.789123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모든 클래스에 대한 예측 결과를 하나의 문자열로 합침\n",
    "test_info['target'] = predictions\n",
    "test_info = test_info.reset_index().rename(columns={\"index\": \"ID\"})\n",
    "test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4efd2f6-d74a-491b-a7b1-fd7cf96f45a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T03:31:45.295500Z",
     "iopub.status.busy": "2024-09-24T03:31:45.295248Z",
     "iopub.status.idle": "2024-09-24T03:31:45.306856Z",
     "shell.execute_reply": "2024-09-24T03:31:45.306350Z"
    },
    "papermill": {
     "duration": 3.237238,
     "end_time": "2024-09-24T03:31:45.307962",
     "exception": false,
     "start_time": "2024-09-24T03:31:42.070724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 예측 결과를 CSV 파일로 저장\n",
    "test_info.to_csv(\"result.csv\", index=False)\n",
    "print(f\"추론 결과가 result.csv 파일로 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67616.64487,
   "end_time": "2024-09-24T03:32:08.718839",
   "environment_variables": {},
   "exception": null,
   "input_path": "code8_ca_v2.ipynb",
   "output_path": "code8_ca_v2_result.ipynb",
   "parameters": {},
   "start_time": "2024-09-23T08:45:12.073969",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
